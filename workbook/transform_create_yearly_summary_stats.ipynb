{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Takes in the raw data game data just after the scrape and creates yearly summary stats for team\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import ast # for literal_eval function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_2484\\4288072279.py:3: DtypeWarning: Columns (11,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  games_df = pd.read_csv('../data/cfb_scrape_raw.csv')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load Data\n",
    "conference_df = pd.read_csv('../data/yearly_conference_members.csv')\n",
    "games_df = pd.read_csv('../data/cfb_scrape_raw.csv')\n",
    "\n",
    "# rename Unnamed: 0 to year in conference_df\n",
    "conference_df = conference_df.rename(columns={'Unnamed: 0': 'Year'})\n",
    "\n",
    "\n",
    "\n",
    "# Convert string representations of lists back into actual lists\n",
    "for col in conference_df.columns[1:]:\n",
    "    conference_df[col] = conference_df[col].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_2484\\991721257.py:23: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  games_df['Winner'] = games_df['Winner'].str.replace(r'^\\(\\d+\\)\\s', '')\n",
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_2484\\991721257.py:24: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  games_df['Loser'] = games_df['Loser'].str.replace(r'^\\(\\d+\\)\\s', '')\n"
     ]
    }
   ],
   "source": [
    "### Extract the ranking from the team name where applicable\n",
    "## Pool ranking is contained in parentheses at the beginning of the team name string of the Winner and Loser columns\n",
    "def extract_ranking(team_name):\n",
    "    \"\"\"Extract the ranking from the team name where applicable.\"\"\"\n",
    "    # If the team name does not start with a parenthesis, there is no ranking\n",
    "    if team_name[0] != '(':\n",
    "        return None\n",
    "    \n",
    "    # Find the closing parenthesis\n",
    "    closing_paren = team_name.find(')')\n",
    "    \n",
    "    # Extract the ranking\n",
    "    ranking = team_name[1:closing_paren]\n",
    "    \n",
    "    return ranking\n",
    "\n",
    "# Apply function to Winner column and save in new 'Winner_Rank' column\n",
    "games_df['Winner_Rank'] = games_df['Winner'].apply(extract_ranking)\n",
    "# Apply function to Loser column and save in new 'Loser_Rank' column\n",
    "games_df['Loser_Rank'] = games_df['Loser'].apply(extract_ranking)\n",
    "\n",
    "# Remove the ranking from the team name but only from the front of the string\n",
    "games_df['Winner'] = games_df['Winner'].str.replace(r'^\\(\\d+\\)\\s', '')\n",
    "games_df['Loser'] = games_df['Loser'].str.replace(r'^\\(\\d+\\)\\s', '')\n",
    "\n",
    "# Strip leading and trailing whitespace from team names\n",
    "games_df['Winner'] = games_df['Winner'].str.strip()\n",
    "games_df['Loser'] = games_df['Loser'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conference_df = pd.read_csv('../data/yearly_conference_members.csv')\n",
    "\n",
    "# rename Unnamed: 0 to year in conference_df\n",
    "conference_df = conference_df.rename(columns={'Unnamed: 0': 'Year'})\n",
    "\n",
    "# Convert string representations of lists back into actual lists\n",
    "for col in conference_df.columns[1:]:\n",
    "    conference_df[col] = conference_df[col].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "\n",
    "# Function to retrieve the conference based on year and team name\n",
    "def get_conference(year, team_name, conference_lookup):\n",
    "    \"\"\"\n",
    "    Given a year and team name, retrieve the conference the team belongs to.\n",
    "    If no conference found, return \"Independent/Unknown\".\n",
    "    \"\"\"\n",
    "    return conference_lookup.get((year, team_name), \"Independent/Unknown\")\n",
    "\n",
    "# Create a lookup dictionary for team-year to conference mapping\n",
    "conference_lookup = {}\n",
    "\n",
    "for _, row in conference_df.iterrows():\n",
    "    year = row['Year']\n",
    "    for col, teams in row[1:].items():\n",
    "        for team in teams:\n",
    "            conference_lookup[(year, team)] = col\n",
    "\n",
    "# Use funtion to assign conference affiliation the teams in each row but only if \n",
    "# the team name is not null\n",
    "games_df['winner_conference'] = games_df.apply(lambda row: get_conference(row['Season'], row['Winner'], conference_lookup) if pd.notna(row['Winner']) else None, axis=1)\n",
    "games_df['loser_conference'] = games_df.apply(lambda row: get_conference(row['Season'], row['Loser'], conference_lookup) if pd.notna(row['Loser']) else None, axis=1)\n",
    "\n",
    "\n",
    "### Create a new column for conference and non-conference games\n",
    "# Function to determine if a game is a conference game\n",
    "def determine_conference_game(conference1, conference2):\n",
    "    if conference1 == conference2:\n",
    "        return 'Conference'\n",
    "    else:\n",
    "        return 'Non-Conference'\n",
    "    \n",
    "# Apply to create new 'game_type' column using the determine_conference_game function and the winner and loser conference columns\n",
    "games_df['game_type'] = games_df.apply(lambda row: determine_conference_game(row['winner_conference'], row['loser_conference']) if pd.notna(row['winner_conference']) and pd.notna(row['loser_conference']) else None, axis=1)\n",
    "\n",
    "# Set game type to Non-Conferecne if either team is Independent/Unknown\n",
    "games_df.loc[games_df['winner_conference'] == 'Independent/Unknown', 'game_type'] = 'Non-Conference'\n",
    "games_df.loc[games_df['loser_conference'] == 'Independent/Unknown', 'game_type'] = 'Non-Conference'\n",
    "\n",
    "# Rename the points columns to be more to match code down the line\n",
    "# Pts = winner_pts, Pts.1 = loser_pts\n",
    "games_df = games_df.rename(columns={'Pts': 'winner_pts', 'Pts.1': 'loser_pts'})\n",
    "\n",
    "# season_year to season\n",
    "games_df = games_df.rename(columns={'Season': 'season'})\n",
    "\n",
    "# unnamed: 6 to loc_ind\n",
    "games_df = games_df.rename(columns={'Unnamed: 6': 'loc_ind'})\n",
    "# unameed: 7 to loc_ind_2\n",
    "games_df = games_df.rename(columns={'Unnamed: 7': 'loc_ind_2'})\n",
    "# combine loc_ind and loc_ind_2 to loc_ind\n",
    "games_df['loc_ind'] = games_df['loc_ind'].fillna(games_df['loc_ind_2'])\n",
    "\n",
    "# drop loc_ind_2\n",
    "games_df = games_df.drop(columns=['loc_ind_2'])\n",
    "\n",
    "# make all column names lowercase\n",
    "games_df.columns = games_df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Classify games base on Notes column (creating seperate columns for conf_champ_games, bowl_games, playoff_games)\n",
    "\n",
    "# Do The playoff first to make filtering out the conf_champ games easier\n",
    "# Function to determine if a game is a playoff game\n",
    "def determine_playoff_game(notes):\n",
    "    if pd.notna(notes) and 'Playoff' in notes:\n",
    "        return notes\n",
    "    else:\n",
    "        return ''\n",
    "    \n",
    "# run function\n",
    "games_df['playoff_game'] = games_df['notes'].apply(determine_playoff_game)\n",
    "# If the playoff_game column is not empty clear the notes column\n",
    "games_df.loc[games_df['playoff_game'] != '', 'notes'] = ''\n",
    "\n",
    "# Function to determine if a game is a conference championship game\n",
    "def determine_conf_champ_game(notes):\n",
    "    if pd.notna(notes) and 'Championship' in notes:\n",
    "        return notes\n",
    "    else:\n",
    "        return ''\n",
    "# run function\n",
    "games_df['conf_champ_game'] = games_df['notes'].apply(determine_conf_champ_game)\n",
    "# If the conf_champ_game column is not empty clear the notes column\n",
    "games_df.loc[games_df['conf_champ_game'] != '', 'notes'] = ''\n",
    "\n",
    "# Classify bowl games\n",
    "# Function to determine if a game is a bowl game\n",
    "def determine_bowl_game(notes):\n",
    "    if pd.notna(notes) and 'Bowl' in notes:\n",
    "        return notes\n",
    "    else:\n",
    "        return ''\n",
    "    \n",
    "# run function\n",
    "games_df['bowl_game'] = games_df['notes'].apply(determine_bowl_game)\n",
    "# If the bowl_game column is not empty clear the notes column\n",
    "games_df.loc[games_df['bowl_game'] != '', 'notes'] = ''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81606"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(games_df)\n",
    "# output csv for check\n",
    "# games_df.to_csv('../TEMP/check.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261\n",
      "81606\n",
      "77718\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['rk', 'wk', 'date', 'day', 'winner', 'winner_pts', 'loc_ind', 'loser',\n",
       "       'loser_pts', 'notes', 'season', 'time', 'winner_rank', 'loser_rank',\n",
       "       'winner_conference', 'loser_conference', 'game_type', 'playoff_game',\n",
       "       'conf_champ_game', 'bowl_game'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## add a filter to only include game that are teams in the ncaa_division_1_fbs dataframe\n",
    "\n",
    "# load the ncaa_division_1_fbs dataframe\n",
    "ncaa_df = pd.read_csv('../data/ncaa_com_fbs_fcs_table_with_location.csv')\n",
    "ncaa_df.columns\n",
    "\n",
    "# simple_name to a list\n",
    "ncaa_names = ncaa_df['simple_name'].tolist()\n",
    "\n",
    "# print length of list\n",
    "\n",
    "print (len(ncaa_names))\n",
    "print (len(games_df))\n",
    "\n",
    "# filter the games_df to only include games from the relevant teams\n",
    "# team name will be in winner or loser column\n",
    "games_df = games_df[games_df['winner'].isin(ncaa_names) | games_df['loser'].isin(ncaa_names)]\n",
    "\n",
    "print(len(games_df))\n",
    "\n",
    "games_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 77718 entries, 0 to 81605\n",
      "Data columns (total 21 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   rk                 77718 non-null  int64  \n",
      " 1   wk                 77718 non-null  int64  \n",
      " 2   date               77718 non-null  object \n",
      " 3   day                77718 non-null  object \n",
      " 4   winner             77718 non-null  object \n",
      " 5   winner_pts         77716 non-null  float64\n",
      " 6   loc_ind            32109 non-null  object \n",
      " 7   loser              77718 non-null  object \n",
      " 8   loser_pts          77716 non-null  float64\n",
      " 9   notes              5158 non-null   object \n",
      " 10  season             77718 non-null  int64  \n",
      " 11  time               7343 non-null   object \n",
      " 12  winner_rank        14813 non-null  object \n",
      " 13  loser_rank         5880 non-null   object \n",
      " 14  winner_conference  77718 non-null  object \n",
      " 15  loser_conference   77718 non-null  object \n",
      " 16  game_type          77718 non-null  object \n",
      " 17  playoff_game       77718 non-null  object \n",
      " 18  conf_champ_game    77718 non-null  object \n",
      " 19  bowl_game          77718 non-null  object \n",
      " 20  margin             77718 non-null  object \n",
      "dtypes: float64(2), int64(3), object(16)\n",
      "memory usage: 13.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# classify game as close or blowout based on the score\n",
    "\n",
    "\n",
    "# absolute value is  less than 7 is close and greater than 21 is blowout\n",
    "def classify_game(row):\n",
    "    if abs(row['winner_pts'] - row['loser_pts']) < 7:\n",
    "        return 'Close'\n",
    "    elif abs(row['winner_pts'] - row['loser_pts']) > 21:\n",
    "        return 'Blowout'\n",
    "    else:\n",
    "        return ''\n",
    "    \n",
    "# apply function to create new column\n",
    "\n",
    "games_df['margin'] = games_df.apply(classify_game, axis=1)\n",
    "\n",
    "\n",
    "games_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column for home Team and away team and move the tean names and score from winners and losers coulmn to \n",
    "## the new columns based on the loc_ind column - leaving the Nuetral games in the winners and losers columns\n",
    "\n",
    "# Function to determine the home team and away team\n",
    "def determine_home_away_team(loc_ind, winner, loser):\n",
    "    if loc_ind == '@':\n",
    "        return loser, winner\n",
    "    elif loc_ind == 'N':\n",
    "        return '', ''\n",
    "    else:\n",
    "        return winner, loser\n",
    "    \n",
    "# Apply function to create new columns for home and away team\n",
    "games_df['home_team'], games_df['away_team'] = zip(*games_df.apply(lambda row: determine_home_away_team(row['loc_ind'], row['winner'], row['loser']), axis=1))\n",
    "\n",
    "# Function to determine the home team score and away team score\n",
    "def determine_home_away_score(loc_ind, winner_pts, loser_pts):\n",
    "    if loc_ind == '@':\n",
    "        return loser_pts, winner_pts\n",
    "    elif loc_ind == 'N':   \n",
    "        return '', ''\n",
    "    else:\n",
    "        return winner_pts, loser_pts\n",
    "\n",
    "# Function to assign the ranking columns to new coumns (home_rank, away_rank) if the game was not nuetral\n",
    "def determine_home_away_rank(loc_ind, winner_rank, loser_rank):\n",
    "    if loc_ind == '@':\n",
    "        return loser_rank, winner_rank\n",
    "    elif loc_ind == 'N':\n",
    "        return '', ''\n",
    "    else:\n",
    "        return winner_rank, loser_rank\n",
    "\n",
    "# apply function to create new columns for home and away team ranks\n",
    "games_df['home_rank'], games_df['away_rank'] = zip(*games_df.apply(lambda row: determine_home_away_rank(row['loc_ind'], row['winner_rank'], row['loser_rank']), axis=1))\n",
    "\n",
    "# # drop the values from winner rank and loser rank columns if they are not nuetral\n",
    "# games_df.loc[games_df['loc_ind'] != 'N', 'winner_rank'] = ''\n",
    "# games_df.loc[games_df['loc_ind'] != 'N', 'loser_rank'] = ''\n",
    "    \n",
    "# Apply function to create new columns for home and away team scores\n",
    "games_df['home_team_score'], games_df['away_team_score'] = zip(*games_df.apply(lambda row: determine_home_away_score(row['loc_ind'], row['winner_pts'], row['loser_pts']), axis=1))\n",
    "\n",
    "\n",
    "# create columns for neutral site games\n",
    "# if the loc_ind column is N then the winner and loser columns are the neutral site winner and loser\n",
    "games_df['neutral_winner'] = games_df.apply(lambda row: row['winner'] if row['loc_ind'] == 'N' else '', axis=1)\n",
    "games_df['neutral_loser'] = games_df.apply(lambda row: row['loser'] if row['loc_ind'] == 'N' else '', axis=1)\n",
    "# clear the @ out of the loc_ind column\n",
    "games_df.loc[games_df['loc_ind'] == '@', 'loc_ind'] = ''\n",
    "# Drop the loc_ind column\n",
    "# games_df = games_df.drop(columns=['loc_ind'])\n",
    "\n",
    "# create column to identify all post season games\n",
    "games_df['post_season_game'] = games_df['playoff_game'] + games_df['conf_champ_game'] + games_df['bowl_game']\n",
    "# change the values to 1 if the game is a post season game\n",
    "games_df.loc[games_df['post_season_game'] != '', 'post_season_game'] = 'yes'\n",
    "# \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.info()\n",
    "# reverse the chronological order of the dataframe\n",
    "# games_df = games_df.iloc[::-1]\n",
    "# games_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_statistics_optimized(df):\n",
    "    # Preprocessing: create columns for each team's points regardless of home/away or winner/loser\n",
    "    df['team1'] = df.apply(lambda x: x['winner'] if x['loc_ind'] == 'N' else x['home_team'], axis=1)\n",
    "    df['team2'] = df.apply(lambda x: x['loser'] if x['loc_ind'] == 'N' else x['away_team'], axis=1)\n",
    "    df['team1_pts'] = df.apply(lambda x: x['winner_pts'] if x['loc_ind'] == 'N' else x['home_team_score'], axis=1)\n",
    "    df['team2_pts'] = df.apply(lambda x: x['loser_pts'] if x['loc_ind'] == 'N' else x['away_team_score'], axis=1)\n",
    "\n",
    "    # Initialize statistics dataframe\n",
    "    columns = ['season', 'team', 'wins', 'losses', 'ties', 'avg_points_scored', 'avg_points_conceded']\n",
    "    stats_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "    # Combine data for both teams into a single dataframe for easier processing\n",
    "    team1_df = df[['season', 'team1', 'team1_pts', 'team2_pts']].rename(columns={'team1': 'team', 'team1_pts': 'scored', 'team2_pts': 'conceded'})\n",
    "    team2_df = df[['season', 'team2', 'team2_pts', 'team1_pts']].rename(columns={'team2': 'team', 'team2_pts': 'scored', 'team1_pts': 'conceded'})\n",
    "    combined = pd.concat([team1_df, team2_df], ignore_index=True)\n",
    "\n",
    "    # Calculate wins, losses, ties and Win %\n",
    "    combined['wins'] = (combined['scored'] > combined['conceded']).astype(int)\n",
    "    combined['losses'] = (combined['scored'] < combined['conceded']).astype(int)\n",
    "    combined['ties'] = (combined['scored'] == combined['conceded']).astype(int)\n",
    "    combined['win_pct'] = combined['wins'] / (combined['wins'] + combined['losses'] + combined['ties'])\n",
    "    # Round to 3 decimal places\n",
    "    combined['win_pct'] = combined['win_pct'].round(3)\n",
    "\n",
    "    # Group by season and team and aggregate results\n",
    "    stats_df = combined.groupby(['season', 'team']).agg(\n",
    "        wins=('wins', 'sum'),\n",
    "        losses=('losses', 'sum'),\n",
    "        ties=('ties', 'sum'),\n",
    "        avg_points_scored=('scored', 'mean'),\n",
    "        avg_points_conceded=('conceded', 'mean')\n",
    "    ).reset_index()\n",
    "\n",
    "    return stats_df\n",
    "\n",
    "# Compute the statistics using the optimized approach\n",
    "team_stats_optimized = compute_statistics_optimized(games_df)\n",
    "team_stats_optimized.tail()\n",
    "df = team_stats_optimized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>team</th>\n",
       "      <th>home_wins</th>\n",
       "      <th>home_losses</th>\n",
       "      <th>home_ties</th>\n",
       "      <th>home_games</th>\n",
       "      <th>away_wins</th>\n",
       "      <th>away_losses</th>\n",
       "      <th>away_ties</th>\n",
       "      <th>away_games</th>\n",
       "      <th>home_points_scored</th>\n",
       "      <th>home_points_allowed</th>\n",
       "      <th>away_points_scored</th>\n",
       "      <th>away_points_allowed</th>\n",
       "      <th>avg_home_points_scored</th>\n",
       "      <th>avg_home_points_allowed</th>\n",
       "      <th>avg_away_points_scored</th>\n",
       "      <th>avg_away_points_allowed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24257</th>\n",
       "      <td>2022</td>\n",
       "      <td>Western Carolina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24258</th>\n",
       "      <td>2022</td>\n",
       "      <td>Western Illinois</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24259</th>\n",
       "      <td>2022</td>\n",
       "      <td>William &amp; Mary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24260</th>\n",
       "      <td>2022</td>\n",
       "      <td>Wofford</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24261</th>\n",
       "      <td>2022</td>\n",
       "      <td>Youngstown State</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       season              team  home_wins  home_losses  home_ties  \\\n",
       "24257    2022  Western Carolina        NaN          NaN        NaN   \n",
       "24258    2022  Western Illinois        NaN          NaN        NaN   \n",
       "24259    2022    William & Mary        NaN          NaN        NaN   \n",
       "24260    2022           Wofford        NaN          NaN        NaN   \n",
       "24261    2022  Youngstown State        NaN          NaN        NaN   \n",
       "\n",
       "       home_games  away_wins  away_losses  away_ties  away_games  \\\n",
       "24257         NaN        0.0          1.0        0.0         1.0   \n",
       "24258         NaN        0.0          1.0        0.0         1.0   \n",
       "24259         NaN        1.0          0.0        0.0         1.0   \n",
       "24260         NaN        0.0          1.0        0.0         1.0   \n",
       "24261         NaN        0.0          1.0        0.0         1.0   \n",
       "\n",
       "       home_points_scored  home_points_allowed  away_points_scored  \\\n",
       "24257                 NaN                  NaN                35.0   \n",
       "24258                 NaN                  NaN                62.0   \n",
       "24259                 NaN                  NaN                41.0   \n",
       "24260                 NaN                  NaN                27.0   \n",
       "24261                 NaN                  NaN                31.0   \n",
       "\n",
       "       away_points_allowed  avg_home_points_scored  avg_home_points_allowed  \\\n",
       "24257                 17.0                     NaN                      NaN   \n",
       "24258                 10.0                     NaN                      NaN   \n",
       "24259                 24.0                     NaN                      NaN   \n",
       "24260                  7.0                     NaN                      NaN   \n",
       "24261                  0.0                     NaN                      NaN   \n",
       "\n",
       "       avg_away_points_scored  avg_away_points_allowed  \n",
       "24257                    35.0                     17.0  \n",
       "24258                    62.0                     10.0  \n",
       "24259                    41.0                     24.0  \n",
       "24260                    27.0                      7.0  \n",
       "24261                    31.0                      0.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Single block of code to calculate home/away records and average points scored and allowed\n",
    "\n",
    "def calculate_team_metrics_v2(df):\n",
    "    # Home Games DataFrame\n",
    "    home_games = df[df['home_team'].notna()].copy()\n",
    "    home_games['home_win'] = (home_games['home_team'] == home_games['winner']).astype(int)\n",
    "    home_games['home_tie'] = (home_games['winner_pts'] == home_games['loser_pts']).astype(int)\n",
    "    home_games['home_loss'] = 1 - home_games['home_win'] - home_games['home_tie']\n",
    "\n",
    "    # Away Games DataFrame\n",
    "    away_games = df[df['away_team'].notna()].copy()\n",
    "    away_games['away_win'] = (away_games['away_team'] == away_games['winner']).astype(int)\n",
    "    away_games['away_tie'] = (away_games['winner_pts'] == away_games['loser_pts']).astype(int)\n",
    "    away_games['away_loss'] = 1 - away_games['away_win'] - away_games['away_tie']\n",
    "\n",
    "    # Grouping by season and team for home and away records\n",
    "    home_record = home_games.groupby(['season', 'home_team']).agg(\n",
    "        home_wins=('home_win', 'sum'),\n",
    "        home_ties=('home_tie', 'sum'),\n",
    "        home_losses=('home_loss', 'sum'),\n",
    "        home_games=('home_win', 'count')\n",
    "    ).reset_index()\n",
    "\n",
    "    away_record = away_games.groupby(['season', 'away_team']).agg(\n",
    "        away_wins=('away_win', 'sum'),\n",
    "        away_ties=('away_tie', 'sum'),\n",
    "        away_losses=('away_loss', 'sum'),\n",
    "        away_games=('away_win', 'count')\n",
    "    ).reset_index()\n",
    "\n",
    "    # Grouping by season and team for home and away points\n",
    "    home_points = home_games.groupby(['season', 'home_team']).agg(\n",
    "        home_points_scored=('winner_pts', 'sum'),\n",
    "        home_points_allowed=('loser_pts', 'sum')\n",
    "    ).reset_index()\n",
    "\n",
    "    away_points = away_games.groupby(['season', 'away_team']).agg(\n",
    "        away_points_scored=('winner_pts', 'sum'),\n",
    "        away_points_allowed=('loser_pts', 'sum')\n",
    "    ).reset_index()\n",
    "\n",
    "    # Merging records and points DataFrames\n",
    "    merged_record = pd.merge(home_record, away_record, left_on=['season', 'home_team'], right_on=['season', 'away_team'], how='outer')\n",
    "    merged_record['team'] = merged_record['home_team'].combine_first(merged_record['away_team'])\n",
    "\n",
    "    merged_points = pd.merge(home_points, away_points, left_on=['season', 'home_team'], right_on=['season', 'away_team'], how='outer')\n",
    "    merged_points['team'] = merged_points['home_team'].combine_first(merged_points['away_team'])\n",
    "\n",
    "    merged_record.drop(['home_team', 'away_team'], axis=1, inplace=True)\n",
    "    merged_points.drop(['home_team', 'away_team'], axis=1, inplace=True)\n",
    "\n",
    "    final_df = pd.merge(merged_record, merged_points, on=['season', 'team'], how='outer')\n",
    "\n",
    "    # Calculating average points\n",
    "    final_df['avg_home_points_scored'] = final_df['home_points_scored'] / final_df['home_games']\n",
    "    final_df['avg_home_points_allowed'] = final_df['home_points_allowed'] / final_df['home_games']\n",
    "    final_df['avg_away_points_scored'] = final_df['away_points_scored'] / final_df['away_games']\n",
    "    final_df['avg_away_points_allowed'] = final_df['away_points_allowed'] / final_df['away_games']\n",
    "\n",
    "    # Reordering the columns for better readability\n",
    "    reordered_columns = [\n",
    "        'season', 'team', \n",
    "        'home_wins', 'home_losses', 'home_ties', 'home_games',\n",
    "        'away_wins', 'away_losses', 'away_ties', 'away_games',\n",
    "        'home_points_scored', 'home_points_allowed',\n",
    "        'away_points_scored', 'away_points_allowed',\n",
    "        'avg_home_points_scored', 'avg_home_points_allowed',\n",
    "        'avg_away_points_scored', 'avg_away_points_allowed'\n",
    "    ]\n",
    "    final_df = final_df[reordered_columns]\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "# Run the refactored function on the existing DataFrame\n",
    "home_away_df = calculate_team_metrics_v2(games_df)\n",
    "home_away_df.tail()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEMP CSV FOR CHECK\n",
    "# Reverse the chronological order of the dataframe\n",
    "games_df = games_df.iloc[::-1]\n",
    "\n",
    "# # reduce the games_df to only include the years 1992 to the present\n",
    "# games_df = games_df[games_df['season'] >= 2001]\n",
    "# games_df.to_csv('../TEMP/check_partaial.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# games_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = games_df\n",
    "## create rules for new dataframes slices\n",
    "# 1. All games\n",
    "# 2. Conference games - tagged in game type column\n",
    "conf_df = df[df['game_type'] == 'Conference']\n",
    "# 3. Non-Conference games - tagged in game type column\n",
    "non_conf_df = df[df['game_type'] == 'Non-Conference']\n",
    "# 4. All-Postseason Games - postseason column not empty\n",
    "post_season_df = df[df['post_season_game'] != '']\n",
    "# 5. Regular season games\n",
    "reg_season_df = df[df['post_season_game'] == '']\n",
    "# 6. Close Games - games with a margin of victory of 7 or less - tagged in margin column\n",
    "close_games_df = df[df['margin'] == 'Close']\n",
    "# 7. Blowout Games - games with a margin of victory of 21 or more - tagged in margin column\n",
    "blowout_games_df = df[df['margin'] == 'Blowout']\n",
    "# Neutral site games - neutral_winner column not empty\n",
    "neutral_site_df = df[df['neutral_winner'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# away_games_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_2484\\3946357835.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['team1'] = df.apply(lambda x: x['winner'] if x['loc_ind'] == 'N' else x['home_team'], axis=1)\n",
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_2484\\3946357835.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['team2'] = df.apply(lambda x: x['loser'] if x['loc_ind'] == 'N' else x['away_team'], axis=1)\n",
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_2484\\3946357835.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['team1_pts'] = df.apply(lambda x: x['winner_pts'] if x['loc_ind'] == 'N' else x['home_team_score'], axis=1)\n",
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_2484\\3946357835.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['team2_pts'] = df.apply(lambda x: x['loser_pts'] if x['loc_ind'] == 'N' else x['away_team_score'], axis=1)\n",
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_2484\\3946357835.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['team1'] = df.apply(lambda x: x['winner'] if x['loc_ind'] == 'N' else x['home_team'], axis=1)\n",
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_2484\\3946357835.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['team2'] = df.apply(lambda x: x['loser'] if x['loc_ind'] == 'N' else x['away_team'], axis=1)\n",
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_2484\\3946357835.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['team1_pts'] = df.apply(lambda x: x['winner_pts'] if x['loc_ind'] == 'N' else x['home_team_score'], axis=1)\n",
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_2484\\3946357835.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['team2_pts'] = df.apply(lambda x: x['loser_pts'] if x['loc_ind'] == 'N' else x['away_team_score'], axis=1)\n",
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_2484\\3946357835.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['team1'] = df.apply(lambda x: x['winner'] if x['loc_ind'] == 'N' else x['home_team'], axis=1)\n",
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_2484\\3946357835.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['team2'] = df.apply(lambda x: x['loser'] if x['loc_ind'] == 'N' else x['away_team'], axis=1)\n",
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_2484\\3946357835.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['team1_pts'] = df.apply(lambda x: x['winner_pts'] if x['loc_ind'] == 'N' else x['home_team_score'], axis=1)\n",
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_2484\\3946357835.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['team2_pts'] = df.apply(lambda x: x['loser_pts'] if x['loc_ind'] == 'N' else x['away_team_score'], axis=1)\n",
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_2484\\3946357835.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['team1'] = df.apply(lambda x: x['winner'] if x['loc_ind'] == 'N' else x['home_team'], axis=1)\n",
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_2484\\3946357835.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['team2'] = df.apply(lambda x: x['loser'] if x['loc_ind'] == 'N' else x['away_team'], axis=1)\n",
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_2484\\3946357835.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['team1_pts'] = df.apply(lambda x: x['winner_pts'] if x['loc_ind'] == 'N' else x['home_team_score'], axis=1)\n",
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_2484\\3946357835.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['team2_pts'] = df.apply(lambda x: x['loser_pts'] if x['loc_ind'] == 'N' else x['away_team_score'], axis=1)\n",
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_2484\\3946357835.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['team1'] = df.apply(lambda x: x['winner'] if x['loc_ind'] == 'N' else x['home_team'], axis=1)\n",
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_2484\\3946357835.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['team2'] = df.apply(lambda x: x['loser'] if x['loc_ind'] == 'N' else x['away_team'], axis=1)\n",
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_2484\\3946357835.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['team1_pts'] = df.apply(lambda x: x['winner_pts'] if x['loc_ind'] == 'N' else x['home_team_score'], axis=1)\n",
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_2484\\3946357835.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['team2_pts'] = df.apply(lambda x: x['loser_pts'] if x['loc_ind'] == 'N' else x['away_team_score'], axis=1)\n",
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_2484\\3946357835.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['team1'] = df.apply(lambda x: x['winner'] if x['loc_ind'] == 'N' else x['home_team'], axis=1)\n",
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_2484\\3946357835.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['team2'] = df.apply(lambda x: x['loser'] if x['loc_ind'] == 'N' else x['away_team'], axis=1)\n",
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_2484\\3946357835.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['team1_pts'] = df.apply(lambda x: x['winner_pts'] if x['loc_ind'] == 'N' else x['home_team_score'], axis=1)\n",
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_2484\\3946357835.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['team2_pts'] = df.apply(lambda x: x['loser_pts'] if x['loc_ind'] == 'N' else x['away_team_score'], axis=1)\n",
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_2484\\3946357835.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['team1'] = df.apply(lambda x: x['winner'] if x['loc_ind'] == 'N' else x['home_team'], axis=1)\n",
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_2484\\3946357835.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['team2'] = df.apply(lambda x: x['loser'] if x['loc_ind'] == 'N' else x['away_team'], axis=1)\n",
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_2484\\3946357835.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['team1_pts'] = df.apply(lambda x: x['winner_pts'] if x['loc_ind'] == 'N' else x['home_team_score'], axis=1)\n",
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_2484\\3946357835.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['team2_pts'] = df.apply(lambda x: x['loser_pts'] if x['loc_ind'] == 'N' else x['away_team_score'], axis=1)\n"
     ]
    }
   ],
   "source": [
    "# LOOP THROUGH ALL SITUATIONAL DATAFRAMES AND AGGRIGATE IT ALL INTO A SINGLE TABLE\n",
    "# Create a dictionary of dataframes and their associated prefixes\n",
    "dfs_dict = {\n",
    "    'all': games_df,\n",
    "    'conf': conf_df,\n",
    "    'non_conf': non_conf_df,\n",
    "    'post_season': post_season_df,\n",
    "    'reg_season': reg_season_df,\n",
    "    'close_games': close_games_df,\n",
    "    'blowout_games':blowout_games_df,\n",
    "    'neutral_site': neutral_site_df,\n",
    "    # 'campus_site': final_df_v2,\n",
    "    # 'home_games': home_games_df,\n",
    "    # 'away_games': away_games_df\n",
    "}\n",
    "\n",
    "# Process each dataframe and store the results in a dictionary\n",
    "results_dict = {}\n",
    "for prefix, df_slice in dfs_dict.items():\n",
    "    results_dict[prefix] = compute_statistics_optimized(df_slice)\n",
    "\n",
    "# Join all the results into a single dataframe\n",
    "final_df = results_dict['all'].copy()\n",
    "final_df.columns = ['season', 'team'] + [f'all_{col}' for col in final_df.columns if col not in ['season', 'team']]\n",
    "\n",
    "# Merge the other dataframes using the season and team columns as keys\n",
    "for prefix, result_df in results_dict.items():\n",
    "    if prefix != 'all':\n",
    "        new_cols = [f'{prefix}_{col}' for col in result_df.columns if col not in ['season', 'team']]\n",
    "        result_df.columns = ['season', 'team'] + new_cols\n",
    "        final_df = pd.merge(final_df, result_df, on=['season', 'team'], how='outer')\n",
    "\n",
    "# Display a sample of the final dataframe\n",
    "# final_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add the data from the home and away dataframe to the final_df\n",
    "# Merge the other dataframes using the season and team columns as keys\n",
    "\n",
    "# final_df = pd.merge(final_df, home_away_df, on=['season', 'team'], how='outer')\n",
    "\n",
    "\n",
    "# # calculate win percentages for home and away games\n",
    "# home_away_df['home_win_pct'] = home_away_df['home_wins'] / home_away_df['home_games']\n",
    "# home_away_df['away_win_pct'] = home_away_df['away_wins'] / home_away_df['away_games']\n",
    "# # home_away_df.info()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 24461 entries, 0 to 24460\n",
      "Data columns (total 66 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   season                             24461 non-null  int64  \n",
      " 1   team                               24461 non-null  object \n",
      " 2   all_wins                           24314 non-null  float64\n",
      " 3   all_losses                         24314 non-null  float64\n",
      " 4   all_ties                           24314 non-null  float64\n",
      " 5   all_avg_points_scored              24313 non-null  float64\n",
      " 6   all_avg_points_conceded            24313 non-null  float64\n",
      " 7   conf_wins                          7301 non-null   float64\n",
      " 8   conf_losses                        7301 non-null   float64\n",
      " 9   conf_ties                          7301 non-null   float64\n",
      " 10  conf_avg_points_scored             7301 non-null   float64\n",
      " 11  conf_avg_points_conceded           7301 non-null   float64\n",
      " 12  non_conf_wins                      24267 non-null  float64\n",
      " 13  non_conf_losses                    24267 non-null  float64\n",
      " 14  non_conf_ties                      24267 non-null  float64\n",
      " 15  non_conf_avg_points_scored         24266 non-null  float64\n",
      " 16  non_conf_avg_points_conceded       24266 non-null  float64\n",
      " 17  post_season_wins                   3146 non-null   float64\n",
      " 18  post_season_losses                 3146 non-null   float64\n",
      " 19  post_season_ties                   3146 non-null   float64\n",
      " 20  post_season_avg_points_scored      3146 non-null   float64\n",
      " 21  post_season_avg_points_conceded    3146 non-null   float64\n",
      " 22  reg_season_wins                    24275 non-null  float64\n",
      " 23  reg_season_losses                  24275 non-null  float64\n",
      " 24  reg_season_ties                    24275 non-null  float64\n",
      " 25  reg_season_avg_points_scored       24274 non-null  float64\n",
      " 26  reg_season_avg_points_conceded     24274 non-null  float64\n",
      " 27  close_games_wins                   15441 non-null  float64\n",
      " 28  close_games_losses                 15441 non-null  float64\n",
      " 29  close_games_ties                   15441 non-null  float64\n",
      " 30  close_games_avg_points_scored      15441 non-null  float64\n",
      " 31  close_games_avg_points_conceded    15441 non-null  float64\n",
      " 32  blowout_games_wins                 19171 non-null  float64\n",
      " 33  blowout_games_losses               19171 non-null  float64\n",
      " 34  blowout_games_ties                 19171 non-null  float64\n",
      " 35  blowout_games_avg_points_scored    19171 non-null  float64\n",
      " 36  blowout_games_avg_points_conceded  19171 non-null  float64\n",
      " 37  neutral_site_wins                  5462 non-null   float64\n",
      " 38  neutral_site_losses                5462 non-null   float64\n",
      " 39  neutral_site_ties                  5462 non-null   float64\n",
      " 40  neutral_site_avg_points_scored     5462 non-null   float64\n",
      " 41  neutral_site_avg_points_conceded   5462 non-null   float64\n",
      " 42  home_wins                          16522 non-null  float64\n",
      " 43  home_losses                        16522 non-null  float64\n",
      " 44  home_ties                          16522 non-null  float64\n",
      " 45  home_games                         16522 non-null  float64\n",
      " 46  away_wins                          22943 non-null  float64\n",
      " 47  away_losses                        22943 non-null  float64\n",
      " 48  away_ties                          22943 non-null  float64\n",
      " 49  away_games                         22943 non-null  float64\n",
      " 50  home_points_scored                 16522 non-null  float64\n",
      " 51  home_points_allowed                16522 non-null  float64\n",
      " 52  away_points_scored                 22943 non-null  float64\n",
      " 53  away_points_allowed                22943 non-null  float64\n",
      " 54  avg_home_points_scored             16522 non-null  float64\n",
      " 55  avg_home_points_allowed            16522 non-null  float64\n",
      " 56  avg_away_points_scored             22943 non-null  float64\n",
      " 57  avg_away_points_allowed            22943 non-null  float64\n",
      " 58  all_win_pct                        24313 non-null  float64\n",
      " 59  conf_win_pct                       7301 non-null   float64\n",
      " 60  non_conf_win_pct                   24266 non-null  float64\n",
      " 61  post_season_win_pct                3146 non-null   float64\n",
      " 62  reg_season_win_pct                 24274 non-null  float64\n",
      " 63  close_games_win_pct                15441 non-null  float64\n",
      " 64  blowout_games_win_pct              19171 non-null  float64\n",
      " 65  neutral_site_win_pct               5462 non-null   float64\n",
      "dtypes: float64(64), int64(1), object(1)\n",
      "memory usage: 12.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# Use the season and team columns as keys to merge the dataframes and add the home/away data to new columns\n",
    "final_df = pd.merge(final_df, home_away_df, on=['season', 'team'], how='outer')\n",
    "\n",
    "# do the win percentage calculation for all of the catagories in the final_df - all, conf, non_conf, post_season, reg_season, close_games, blowout_games, neutral_site\n",
    "# calculate win percentages for all games\n",
    "final_df['all_win_pct'] = final_df['all_wins'] / (final_df['all_wins'] + final_df['all_losses'] + final_df['all_ties'])\n",
    "# calculate win percentages for conference games\n",
    "final_df['conf_win_pct'] = final_df['conf_wins'] / (final_df['conf_wins'] + final_df['conf_losses'] + final_df['conf_ties'])\n",
    "# calculate win percentages for non-conference games\n",
    "final_df['non_conf_win_pct'] = final_df['non_conf_wins'] / (final_df['non_conf_wins'] + final_df['non_conf_losses'] + final_df['non_conf_ties'])\n",
    "# calculate win percentages for post-season games\n",
    "final_df['post_season_win_pct'] = final_df['post_season_wins'] / (final_df['post_season_wins'] + final_df['post_season_losses'] + final_df['post_season_ties'])\n",
    "# calculate win percentages for regular season games\n",
    "final_df['reg_season_win_pct'] = final_df['reg_season_wins'] / (final_df['reg_season_wins'] + final_df['reg_season_losses'] + final_df['reg_season_ties'])\n",
    "# calculate win percentages for close games\n",
    "final_df['close_games_win_pct'] = final_df['close_games_wins'] / (final_df['close_games_wins'] + final_df['close_games_losses'] + final_df['close_games_ties'])\n",
    "# calculate win percentages for blowout games\n",
    "final_df['blowout_games_win_pct'] = final_df['blowout_games_wins'] / (final_df['blowout_games_wins'] + final_df['blowout_games_losses'])\n",
    "# calculate win percentages for neutral site games\n",
    "final_df['neutral_site_win_pct'] = final_df['neutral_site_wins'] / (final_df['neutral_site_wins'] + final_df['neutral_site_losses'] + final_df['neutral_site_ties'])\n",
    "\n",
    "\n",
    "# Display a sample of the final dataframe\n",
    "final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add conference affiliation to teams\n",
    "import ast # for literal_eval function\n",
    "\n",
    "conference_df = pd.read_csv('../data/yearly_conference_members.csv')\n",
    "\n",
    "# rename Unnamed: 0 to year in conference_df\n",
    "conference_df = conference_df.rename(columns={'Unnamed: 0': 'Year'})\n",
    "\n",
    "# Convert string representations of lists back into actual lists\n",
    "for col in conference_df.columns[1:]:\n",
    "    conference_df[col] = conference_df[col].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "\n",
    "# Function to retrieve the conference based on year and team name\n",
    "def get_conference(year, team_name, conference_lookup):\n",
    "    \"\"\"\n",
    "    Given a year and team name, retrieve the conference the team belongs to.\n",
    "    If no conference found, return \"Independent/Unknown\".\n",
    "    \"\"\"\n",
    "    return conference_lookup.get((year, team_name), \"Independent/Unknown\")\n",
    "\n",
    "# Create a lookup dictionary for team-year to conference mapping\n",
    "conference_lookup = {}\n",
    "\n",
    "for _, row in conference_df.iterrows():\n",
    "    year = row['Year']\n",
    "    for col, teams in row[1:].items():\n",
    "        for team in teams:\n",
    "            conference_lookup[(year, team)] = col\n",
    "\n",
    "## Add conference affiliation to teams\n",
    "final_df['conference'] = final_df.apply(lambda row: get_conference(row['season'], row['team'], conference_lookup), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.columns\n",
    "\n",
    "# Change all win lose and tie columns to integers\n",
    "# create list of columns to change\n",
    "\n",
    "# list of columns that should be integers\n",
    "# all coulmns with win, lose, tie in the name should be integers\n",
    "int_cols = ['all_wins', 'all_losses', 'all_ties', \n",
    "            'conf_wins', 'conf_losses', 'conf_ties', \n",
    "            'non_conf_wins', 'non_conf_losses', 'non_conf_ties', \n",
    "            'post_season_wins', 'post_season_losses', 'post_season_ties', \n",
    "            'reg_season_wins', 'reg_season_losses', 'reg_season_ties', \n",
    "            'neutral_site_wins', 'neutral_site_losses', 'neutral_site_ties',\n",
    "            'close_games_wins', 'close_games_losses', \n",
    "            'blowout_games_wins', 'blowout_games_losses']\n",
    "\n",
    "# fill and null values with 0\n",
    "final_df[int_cols] = final_df[int_cols].fillna(0)\n",
    "            \n",
    "\n",
    "final_df['all_wins'] = final_df['all_wins'].astype(int)\n",
    "final_df['all_losses'] = final_df['all_losses'].astype(int)\n",
    "final_df['all_ties'] = final_df['all_ties'].astype(int)\n",
    "final_df['conf_wins'] = final_df['conf_wins'].astype(int)\n",
    "final_df['conf_losses'] = final_df['conf_losses'].astype(int)\n",
    "final_df['conf_ties'] = final_df['conf_ties'].astype(int)\n",
    "final_df['non_conf_wins'] = final_df['non_conf_wins'].astype(int)\n",
    "final_df['non_conf_losses'] = final_df['non_conf_losses'].astype(int)\n",
    "final_df['non_conf_ties'] = final_df['non_conf_ties'].astype(int)\n",
    "final_df['post_season_wins'] = final_df['post_season_wins'].astype(int)\n",
    "final_df['post_season_losses'] = final_df['post_season_losses'].astype(int)\n",
    "final_df['post_season_ties'] = final_df['post_season_ties'].astype(int)\n",
    "final_df['reg_season_wins'] = final_df['reg_season_wins'].astype(int)\n",
    "final_df['reg_season_losses'] = final_df['reg_season_losses'].astype(int)\n",
    "final_df['reg_season_ties'] = final_df['reg_season_ties'].astype(int)\n",
    "final_df['close_games_wins'] = final_df['close_games_wins'].astype(int)\n",
    "final_df['close_games_losses'] = final_df['close_games_losses'].astype(int)\n",
    "final_df['blowout_games_wins'] = final_df['blowout_games_wins'].astype(int)\n",
    "final_df['blowout_games_losses'] = final_df['blowout_games_losses'].astype(int)\n",
    "final_df['neutral_site_wins'] = final_df['neutral_site_wins'].astype(int)\n",
    "final_df['neutral_site_losses'] = final_df['neutral_site_losses'].astype(int)\n",
    "final_df['neutral_site_ties'] = final_df['neutral_site_ties'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 24461 entries, 0 to 24460\n",
      "Data columns (total 67 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   season                             24461 non-null  int64  \n",
      " 1   team                               24461 non-null  object \n",
      " 2   all_wins                           24461 non-null  int32  \n",
      " 3   all_losses                         24461 non-null  int32  \n",
      " 4   all_ties                           24461 non-null  int32  \n",
      " 5   all_avg_points_scored              24313 non-null  float64\n",
      " 6   all_avg_points_conceded            24313 non-null  float64\n",
      " 7   conf_wins                          24461 non-null  int32  \n",
      " 8   conf_losses                        24461 non-null  int32  \n",
      " 9   conf_ties                          24461 non-null  int32  \n",
      " 10  conf_avg_points_scored             7301 non-null   float64\n",
      " 11  conf_avg_points_conceded           7301 non-null   float64\n",
      " 12  non_conf_wins                      24461 non-null  int32  \n",
      " 13  non_conf_losses                    24461 non-null  int32  \n",
      " 14  non_conf_ties                      24461 non-null  int32  \n",
      " 15  non_conf_avg_points_scored         24266 non-null  float64\n",
      " 16  non_conf_avg_points_conceded       24266 non-null  float64\n",
      " 17  post_season_wins                   24461 non-null  int32  \n",
      " 18  post_season_losses                 24461 non-null  int32  \n",
      " 19  post_season_ties                   24461 non-null  int32  \n",
      " 20  post_season_avg_points_scored      3146 non-null   float64\n",
      " 21  post_season_avg_points_conceded    3146 non-null   float64\n",
      " 22  reg_season_wins                    24461 non-null  int32  \n",
      " 23  reg_season_losses                  24461 non-null  int32  \n",
      " 24  reg_season_ties                    24461 non-null  int32  \n",
      " 25  reg_season_avg_points_scored       24274 non-null  float64\n",
      " 26  reg_season_avg_points_conceded     24274 non-null  float64\n",
      " 27  close_games_wins                   24461 non-null  int32  \n",
      " 28  close_games_losses                 24461 non-null  int32  \n",
      " 29  close_games_ties                   15441 non-null  float64\n",
      " 30  close_games_avg_points_scored      15441 non-null  float64\n",
      " 31  close_games_avg_points_conceded    15441 non-null  float64\n",
      " 32  blowout_games_wins                 24461 non-null  int32  \n",
      " 33  blowout_games_losses               24461 non-null  int32  \n",
      " 34  blowout_games_ties                 19171 non-null  float64\n",
      " 35  blowout_games_avg_points_scored    19171 non-null  float64\n",
      " 36  blowout_games_avg_points_conceded  19171 non-null  float64\n",
      " 37  neutral_site_wins                  24461 non-null  int32  \n",
      " 38  neutral_site_losses                24461 non-null  int32  \n",
      " 39  neutral_site_ties                  24461 non-null  int32  \n",
      " 40  neutral_site_avg_points_scored     5462 non-null   float64\n",
      " 41  neutral_site_avg_points_conceded   5462 non-null   float64\n",
      " 42  home_wins                          16522 non-null  float64\n",
      " 43  home_losses                        16522 non-null  float64\n",
      " 44  home_ties                          16522 non-null  float64\n",
      " 45  home_games                         16522 non-null  float64\n",
      " 46  away_wins                          22943 non-null  float64\n",
      " 47  away_losses                        22943 non-null  float64\n",
      " 48  away_ties                          22943 non-null  float64\n",
      " 49  away_games                         22943 non-null  float64\n",
      " 50  home_points_scored                 16522 non-null  float64\n",
      " 51  home_points_allowed                16522 non-null  float64\n",
      " 52  away_points_scored                 22943 non-null  float64\n",
      " 53  away_points_allowed                22943 non-null  float64\n",
      " 54  avg_home_points_scored             16522 non-null  float64\n",
      " 55  avg_home_points_allowed            16522 non-null  float64\n",
      " 56  avg_away_points_scored             22943 non-null  float64\n",
      " 57  avg_away_points_allowed            22943 non-null  float64\n",
      " 58  all_win_pct                        24313 non-null  float64\n",
      " 59  conf_win_pct                       7301 non-null   float64\n",
      " 60  non_conf_win_pct                   24266 non-null  float64\n",
      " 61  post_season_win_pct                3146 non-null   float64\n",
      " 62  reg_season_win_pct                 24274 non-null  float64\n",
      " 63  close_games_win_pct                15441 non-null  float64\n",
      " 64  blowout_games_win_pct              19171 non-null  float64\n",
      " 65  neutral_site_win_pct               5462 non-null   float64\n",
      " 66  conference                         24461 non-null  object \n",
      "dtypes: float64(42), int32(22), int64(1), object(2)\n",
      "memory usage: 10.6+ MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OUTPUT THE FINAL DATAFRAME TO CSV\n",
    "final_df.to_csv('../data/viz_table/year_by_year_team_stats_with_splits.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Games:  77718\n",
      "Conference Games:  21016\n",
      "Non-Conference Games:  56702\n",
      "All Postseason Games:  1848\n",
      "Regular Season Games:  75870\n",
      "Close Games:  19568\n",
      "Blowout Games:  25557\n",
      "Neutral Site Games:  3622\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'campus_site_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Justin\\Desktop\\Project\\cfb_conferences\\workbook\\transform_create_yearly_summary_stats.ipynb Cell 26\u001b[0m line \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Justin/Desktop/Project/cfb_conferences/workbook/transform_create_yearly_summary_stats.ipynb#X36sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mBlowout Games: \u001b[39m\u001b[39m'\u001b[39m, \u001b[39mlen\u001b[39m(blowout_games_df))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Justin/Desktop/Project/cfb_conferences/workbook/transform_create_yearly_summary_stats.ipynb#X36sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mNeutral Site Games: \u001b[39m\u001b[39m'\u001b[39m, \u001b[39mlen\u001b[39m(neutral_site_df))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Justin/Desktop/Project/cfb_conferences/workbook/transform_create_yearly_summary_stats.ipynb#X36sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mCampus Site Games: \u001b[39m\u001b[39m'\u001b[39m, \u001b[39mlen\u001b[39m(campus_site_df))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'campus_site_df' is not defined"
     ]
    }
   ],
   "source": [
    "## Print the length of each dataframe with a description\n",
    "print('All Games: ', len(df))\n",
    "print('Conference Games: ', len(conf_df))\n",
    "print('Non-Conference Games: ', len(non_conf_df))\n",
    "print('All Postseason Games: ', len(post_season_df))\n",
    "print('Regular Season Games: ', len(reg_season_df))\n",
    "print('Close Games: ', len(close_games_df))\n",
    "print('Blowout Games: ', len(blowout_games_df))\n",
    "print('Neutral Site Games: ', len(neutral_site_df))\n",
    "print('Campus Site Games: ', len(campus_site_df))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code to create the split statistics for each team and year\n",
    "# Splits - Overall, Regular Season, home, Away, Nuetral, Conference_Championship, Bowl, Playoff, games while ranked, games vs ranked opponents, games as ranked team\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Chat GPT - Attempt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df.head(30)\n",
    "\n",
    "final_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# save to csv\n",
    "final_df.to_csv('../data/cfb_yearly_summary_stats.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
