{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### create school name matching dictionary\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fuzzywuzzy\n",
    "from fuzzywuzzy import process\n",
    "import re # RegEx for string matching\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in school name data\n",
    "\n",
    "wiki_df = pd.read_csv('../data/cfb_d1_teams_with_coordinates.csv')\n",
    "game_df = pd.read_csv('../data/cfb_scores_all_years.csv')\n",
    "conf_df = pd.read_csv('../data/cfb_conference_members.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_df.head()\n",
    "conf_df.head()\n",
    "game_df.head()\n",
    "# len(wiki_names)\n",
    "# len(game_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cleaning Game Result Data\n",
    "\n",
    "## Extract the ranking from the team name and store as seperate column\n",
    "def extract_ranking(team_name):\n",
    "    match = re.match(r'^\\((\\d{1,2})\\)', team_name)\n",
    "    return int(match.group(1)) if match else np.nan\n",
    "\n",
    "game_df['Winner_Ranking'] = game_df['Winner'].apply(extract_ranking)\n",
    "game_df['Loser_Ranking'] = game_df['Loser'].apply(extract_ranking)\n",
    "\n",
    "# Clean the names\n",
    "game_df['Winner'] = game_df['Winner'].str.replace(r'^\\(\\d{1,2}\\)\\s', '').str.strip()\n",
    "game_df['Loser'] = game_df['Loser'].str.replace(r'^\\(\\d{1,2}\\)\\s', '').str.strip()\n",
    "\n",
    "# Save the updated game results to a new csv - overwriting the old one\n",
    "game_df.to_csv('../data/cfb_scores_all_years.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Manual adjustments to the wiki_conf_df dataframe \n",
    "# change conf_name to match wiki_name - conf names are overly conplicated - already have game data matched to wiki\n",
    "\n",
    "adjustments = {'University of Louisiana at Monroe': 'Louisiana-Monroe',\n",
    "               'Middle Tennessee State University': 'Middle Tennessee',\n",
    "               'North Carolina State University': 'NC State',\n",
    "               'University of North Carolina at Charlotte': 'Charlotte (NC)',\n",
    "               'University of Illinois Urbana–Champaign': 'Illinois',               \n",
    "                'University of Maryland, College Park': 'Maryland',\n",
    "                'University of Wisconsin–Madison': 'Wisconsin',\n",
    "                'Connecticut':'UConn',\n",
    "                'University of Alabama at Birmingham': 'UAB',\n",
    "                'University of North Carolina at Charlotte': 'Charlotte (NC)',\n",
    "                'Arizona State Sun': 'Arizona State',\n",
    "                'Brigham Young University': 'BYU',\n",
    "                'Florida Atlantic University': 'FAU',\n",
    "                'Florida International University': 'FIU',\n",
    "                'Georgia Institute of Technology': 'Georgia Tech',\n",
    "                'Indiana University Bloomington': 'Indiana',\n",
    "                'University of California, Los Angeles': 'UCLA',\n",
    "                'University of California, Berkeley': 'California',\n",
    "                'University of Colorado, Boulder': 'Colorado',\n",
    "                'University of Minnesota, Twin Cities': 'Minnesota',\n",
    "                'University of Nebraska-“Lincoln': 'Nebraska',\n",
    "                'University of North Carolina at Chapel Hill': 'North Carolina',\n",
    "                'Virginia Polytechnic Institute and State University': 'Virginia Tech',\n",
    "                'Virginia Tech *': 'Virginia Tech',\n",
    "                'University of Alabama at Birmingham': 'Alabama-Birmingham (UAB)',\n",
    "                'University of Miami': 'Miami (FL)',\n",
    "                \n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "# apply to the Institution column of the conf_df dataframe\n",
    "conf_df['Institution'] = conf_df['Institution'].replace(adjustments)\n",
    "# overwirtes the conf_names list with the adjusted names\n",
    "conf_names = conf_df['Institution'].tolist()\n",
    "               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "### MOVED TO CONF SCRAPE NOTEBOOK\n",
    "# ## Clean school names from conference table to match wiki names\n",
    "\n",
    "# # remove 'University of' and \"University\" from Institution column\n",
    "# conf_df['Institution'] = conf_df['Institution'].str.replace('University of ', '')\n",
    "# conf_df['Institution'] = conf_df['Institution'].str.replace('University', '')\n",
    "# conf_df['Institution'] = conf_df['Institution'].str.strip()\n",
    "# # remove any citations from Institution column\n",
    "# conf_df['Institution'] = conf_df['Institution'].str.replace('\\[.*\\]', '')\n",
    "\n",
    "# # Remove unessisary city names from Institution column \n",
    "# # drop dash and word after '- '\n",
    "# conf_df['Institution'] = conf_df['Institution'].str.replace('- .*', '')\n",
    "###############################################\n",
    "\n",
    "conf_df.head()\n",
    "\n",
    "# value counts of school names in conference table\n",
    "conf_df['Institution'].value_counts()\n",
    "\n",
    "# # sort alphabetically\n",
    "# conf_df = conf_df.sort_values(by=['Institution'])\n",
    "\n",
    "# # get a list of the cleaned names\n",
    "# conf_names = conf_df['Institution'].tolist()\n",
    "# # drop duplicates\n",
    "# conf_names = list(dict.fromkeys(conf_names))\n",
    "\n",
    "# # len(conf_names)\n",
    "\n",
    "# clean wiki_df 'Team' column of citations\n",
    "wiki_df['Team'] = wiki_df['Team'].str.replace('\\[.*\\]', '')\n",
    "# drop the next word after a comma or a dash\n",
    "wiki_df['Team'] = wiki_df['Team'].str.replace(',.*', '')\n",
    "wiki_df['Team'] = wiki_df['Team'].str.replace('-.*', '')\n",
    "\n",
    "# overwrite the wiki_names list with the cleaned names\n",
    "wiki_names = wiki_df['Team'].tolist()\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique names in conf_names\n",
    "len(conf_names)\n",
    "\n",
    "# sort alphabetically\n",
    "# conf_names.sort()\n",
    "# Temp csv\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for matches in wiki names to conference names\n",
    "# create a dictionary of wiki names and their matches\n",
    "\n",
    "wiki_conf_dict = {}\n",
    "\n",
    "# Loop each wiki name and find the best match in the conference names - output a dataframe with bothe names and the score\n",
    "for wiki_name in wiki_names:\n",
    "    match = process.extractOne(wiki_name, conf_names)\n",
    "    wiki_conf_dict[wiki_name] = match\n",
    "\n",
    "wiki_conf_dict\n",
    "\n",
    "# create a dataframe from the dictionary\n",
    "wiki_conf_df = pd.DataFrame.from_dict(wiki_conf_dict, orient='index')\n",
    "\n",
    "wiki_conf_df.head()\n",
    "\n",
    "# Name and assign columns\n",
    "wiki_conf_df.columns = ['conf_name', 'score']\n",
    "# rename index column\n",
    "wiki_conf_df.index.names = ['wiki_name']\n",
    "wiki_conf_df.head()\n",
    "\n",
    "# # histogram of scores\n",
    "# # wiki_conf_df['score'].hist()\n",
    "\n",
    "# # get all matches with a score of 95 or less \n",
    "# # wiki_conf_df = wiki_conf_df[wiki_conf_df['score'] <= 95]\n",
    "# # save temp csv file\n",
    "# # wiki_conf_df.to_csv('../TEMP/wiki_conf_match_3.csv')\n",
    "\n",
    "# # # create a dictionary of all matches with a score of 95 or better\n",
    "# wiki_conf_dict = wiki_conf_df.to_dict('index')\n",
    "# wiki_conf_dict\n",
    "\n",
    "# # # use the dictionary to create a new column in the conf_df dataframe and apply the name from the dictionary to the wiki_name in the conf_df dataframe where there is a match 90 or above\n",
    "# conf_df['conf_name'] = conf_df['Institution'].map(lambda x: wiki_conf_dict[x]['conf_name'] if x in wiki_conf_dict else np.nan)\n",
    "\n",
    "# # # apply the Name from the dictionary to the wiki_name in the conf_df dataframe where there is a match\n",
    "# # conf_df['conf_name'] = conf_df['Institution'].map(lambda x: wiki_conf_dict[x]['conf_name'] if x in wiki_conf_dict else np.nan)\n",
    "\n",
    "# conf_df.head()\n",
    "\n",
    "# # show matching dataframe\n",
    "# wiki_conf_df.head()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_df.sample(20)\n",
    "# sort the matching dataframe by score\n",
    "wiki_conf_df = wiki_conf_df.sort_values(by=['score'], ascending=False)\n",
    "wiki_conf_df.tail(30)\n",
    "\n",
    "# histogram of scores\n",
    "# wiki_conf_df['score'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Match from the Conf names to the wiki names to check for any missed matches\n",
    "\n",
    "\n",
    "# create a dictionary of wiki names and their matches\n",
    "\n",
    "conf_wiki_dict = {}\n",
    "\n",
    "# Loop each wiki name and find the best match in the conference names - output a dataframe with bothe names and the score\n",
    "for conf_name in conf_names:\n",
    "    match = process.extractOne(conf_name, wiki_names)\n",
    "    conf_wiki_dict[conf_name] = match\n",
    "\n",
    "# Create a dataframe fromt he dictionary\n",
    "conf_wiki_df = pd.DataFrame.from_dict(conf_wiki_dict, orient='index')\n",
    "# Rename the columns\n",
    "conf_wiki_df.columns = ['wiki_name', 'score']\n",
    "\n",
    "# Sort by score\n",
    "conf_wiki_df = conf_wiki_df.sort_values(by=['score'], ascending=False)\n",
    "# conf_wiki_df = conf_wiki_df.sort_values(by=['score'], ascending=False)\n",
    "conf_wiki_df.tail(20)\n",
    "\n",
    "# Histogram of scores\n",
    "conf_wiki_df['score'].hist()\n",
    "\n",
    "# printe number of matches 90+ over matches below 90\n",
    "print(len(conf_wiki_df[conf_wiki_df['score'] >= 95]))\n",
    "print(len(conf_wiki_df[conf_wiki_df['score'] < 95]))\n",
    "# percentage of matches 90+ over matches below 90\n",
    "print(len(conf_wiki_df[conf_wiki_df['score'] >= 95]) / len(conf_wiki_df[conf_wiki_df['score'] < 95]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = conf_wiki_df.tail(80)\n",
    "\n",
    "test_df.tail(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  GAME DATA AND WIKI DATA Need Fixes - \n",
    "\n",
    "# Create a dictionary of the manual adjustments\n",
    "manual_adjustments = {\n",
    "    'Texas-El Paso': 'UTEP',\n",
    "    'Connecticut': 'UConn',\n",
    "    'Central Florida': 'UCF',\n",
    "    'Sam Houston State': 'Sam Houston',\n",
    "    'Texas-San Antonio': 'UTSA',\n",
    "    'Florida International': 'FIU',\n",
    "    'Alabama-Birmingham': 'UAB',\n",
    "    'Southern Methodist': 'SMU',\n",
    "    'Southern California': 'USC',\n",
    "    'Massachusetts': 'UMass',\n",
    "    'Brigham Young': 'BYU',\n",
    "    'Texas Christian': 'TCU',\n",
    "    'Nevada-Las Vegas': 'UNLV',\n",
    "    'Mississippi': 'Ole Miss',\n",
    "    # \"North Carolina\": 'UNC',\n",
    "    'North Carolina State': 'NC State',\n",
    "    'Southern Mississippi': 'Southern Miss',\n",
    "    \n",
    "    'Middle Tennessee State': 'Middle Tennessee'\n",
    "}\n",
    "\n",
    "# Reverse the dictionary\n",
    "reversed = {v: k for k, v in manual_adjustments.items()}    \n",
    "\n",
    "# Replace the names in the winner and loser columns of the  game data using the manual adjustments\n",
    "game_df['Winner'] = game_df['Winner'].replace(manual_adjustments)\n",
    "game_df['Loser'] = game_df['Loser'].replace(manual_adjustments)\n",
    "\n",
    "# create lists of the school names\n",
    "wiki_names = wiki_df['Team'].tolist()\n",
    "game_names = game_df['Winner'].tolist() + game_df['Loser'].tolist()\n",
    "# Unique names from the game data\n",
    "game_names = list(dict.fromkeys(game_names))\n",
    "\n",
    "\n",
    "\n",
    "len(game_names)\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wiki_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import process\n",
    "\n",
    "# Function to get the best matching name using fuzzy matching\n",
    "def get_best_match(name, choices):\n",
    "    best_match, score = process.extractOne(name, choices)\n",
    "    return best_match, score\n",
    "\n",
    "# Mapping game names to wiki names using fuzzy matching\n",
    "name_mapping = {}\n",
    "score_mapping = {}  # to store the matching scores\n",
    "\n",
    "for game_name in game_names:\n",
    "    best_match, score = get_best_match(game_name, wiki_names)\n",
    "    name_mapping[game_name] = best_match\n",
    "    score_mapping[game_name] = score\n",
    "\n",
    "#Create a dataframe with both names and the match score\n",
    "name_match_df = pd.DataFrame.from_dict(name_mapping, orient='index', columns=['Matched_Name'])\n",
    "name_match_df['Score'] = score_mapping.values()\n",
    "# Sort by the match score\n",
    "name_match_df.sort_values(by='Score', ascending=False, inplace=True)\n",
    "name_match_df.head(10)\n",
    "name_match_df.tail(10)\n",
    "\n",
    "# histogram of the match scores\n",
    "name_match_df['Score'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_match_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert dictionary to DataFrame and save to CSV\n",
    "df_mapping = pd.DataFrame(list(name_mapping.items()), columns=['Game Name', 'Wiki Name'])\n",
    "# Sort DataFrame alphabetically by game name\n",
    "df_mapping.sort_values(by=['Game Name'], inplace=True)\n",
    "df_mapping.to_csv('../TEMP/name_mapping_trial.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
