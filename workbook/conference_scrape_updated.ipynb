{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scraping College Football Major Conference Membership Data from Wikipedia\n",
    "\n",
    "# Dependencies\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## NEW BLOCK 9-15-23 ##########\n",
    "### Use Wiki list of Division 1 FBS programs to get list of all conferences\n",
    "### Extract all links from Former Conferences column and store in dataframe of conference, wiki_link\n",
    "\n",
    "# URL of page to be scraped\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_NCAA_Division_I_FBS_football_programs'\n",
    "\n",
    "# Retrieve page with the requests module\n",
    "response = requests.get(url)\n",
    "\n",
    "# Create BeautifulSoup object; parse with 'lxml'\n",
    "soup = BeautifulSoup(response.text, 'lxml')\n",
    "# extract Former Conferences column from table\n",
    "table = soup.find('table', class_='wikitable sortable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the table as a temp plain text file\n",
    "with open('../TEMP/temp.txt', 'w') as f:\n",
    "    f.write(str(table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_13540\\919811544.py:35: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  conf_df['conference'] = conf_df['conference'].str.replace(r\"\\[.*\\]\", \"\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create empty lists to store conference and wiki_link\n",
    "conferences = []\n",
    "wiki_links = []\n",
    "rows = table.findAll('tr')\n",
    "\n",
    "# Loop through the rows to extract data\n",
    "for row in rows[1:]:  # Skip header row\n",
    "    cells = row.findAll('td')\n",
    "    \n",
    "    if len(cells) > 6:  # Ensure there are enough columns to extract \"Former Conferences\"\n",
    "        conf_cell = cells[6]\n",
    "        \n",
    "        # Find all the links within the \"Former Conferences\" cell\n",
    "        links = conf_cell.findAll('a')\n",
    "        \n",
    "        # If there are links, extract conference name and link\n",
    "        if links:\n",
    "            for link in links:\n",
    "                conferences.append(link.text)\n",
    "                wiki_links.append(link.get('href'))\n",
    "        else:\n",
    "            # Extract plain text conferences without links\n",
    "            conf_texts = conf_cell.get_text(separator=\"|\").split('|')\n",
    "            for conf in conf_texts:\n",
    "                conferences.append(conf.strip())\n",
    "                wiki_links.append(np.nan)\n",
    "\n",
    "# Create a DataFrame\n",
    "conf_df = pd.DataFrame({'conference': conferences, 'wiki_link': wiki_links})\n",
    "\n",
    "# Convert the 'conference' column to string type\n",
    "conf_df['conference'] = conf_df['conference'].astype(str)\n",
    "\n",
    "# Now remove citation numbers from conference names\n",
    "conf_df['conference'] = conf_df['conference'].str.replace(r\"\\[.*\\]\", \"\")\n",
    "\n",
    "# Drop duplicates\n",
    "conf_df.drop_duplicates(inplace=True)\n",
    "# Drop any rows with NaN values in wiki_link column\n",
    "conf_df.dropna(subset=['wiki_link'], inplace=True)\n",
    "# Drop any rows with empty strings in conference column\n",
    "conf_df = conf_df[conf_df['conference'] != '']\n",
    "# sort alphabetically\n",
    "conf_df.sort_values(by=['conference'], inplace=True)\n",
    "# If the wiki_link coumn matches and existing row in the dataframe, drop it\n",
    "conf_df.drop_duplicates(subset=['wiki_link'], keep='first', inplace=True)\n",
    "# If the conference column matches and existing row in the dataframe, drop it\n",
    "conf_df.drop_duplicates(subset=['conference'], keep='first', inplace=True)\n",
    "# Display the first 20 rows of the dataframe\n",
    "conf_df.tail(20)\n",
    "\n",
    "len(conf_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_df.tail(40)\n",
    "# conf_df.head(20)\n",
    "# add the wiki link to the end of the wikipedia url\n",
    "conf_df['wiki_link'] = 'https://en.wikipedia.org' + conf_df['wiki_link']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## List of Current Conferences (2023) and their Wikipedia URLs\n",
    "SEC = 'https://en.wikipedia.org/wiki/Southeastern_Conference'\n",
    "ACC = 'https://en.wikipedia.org/wiki/Atlantic_Coast_Conference'\n",
    "B1G = 'https://en.wikipedia.org/wiki/Big_Ten_Conference'\n",
    "PAC12 = 'https://en.wikipedia.org/wiki/Pac-12_Conference'\n",
    "BIG12 = 'https://en.wikipedia.org/wiki/Big_12_Conference'\n",
    "AAC = 'https://en.wikipedia.org/wiki/American_Athletic_Conference'\n",
    "MWC = 'https://en.wikipedia.org/wiki/Mountain_West_Conference'\n",
    "MAC = 'https://en.wikipedia.org/wiki/Mid-American_Conference'\n",
    "CUSA = 'https://en.wikipedia.org/wiki/Conference_USA'\n",
    "SBC = 'https://en.wikipedia.org/wiki/Sun_Belt_Conference'\n",
    "\n",
    "\n",
    "# Defunct Conferences That Have Been Major Conferences\n",
    "SWC = 'https://en.wikipedia.org/wiki/Southwest_Conference'\n",
    "BIG8 = 'https://en.wikipedia.org/wiki/Big_Eight_Conference'\n",
    "BIGEAST = 'https://en.wikipedia.org/wiki/Big_East_Conference_(1979%E2%80%932013)'\n",
    "IVY = 'https://en.wikipedia.org/wiki/Ivy_League'\n",
    "PCC = 'https://en.wikipedia.org/wiki/Pacific_Coast_Conference'\n",
    "BORDER = 'https://en.wikipedia.org/wiki/Border_Conference'\n",
    "MVC = 'https://en.wikipedia.org/wiki/Missouri_Valley_Conference'\n",
    "SKYLINE = 'https://en.wikipedia.org/wiki/Skyline_Conference_(1938%E2%80%931962)'\n",
    "WAC = 'https://en.wikipedia.org/wiki/Western_Athletic_Conference_football'\n",
    "\n",
    "# Create a dataframe of the above conferences and their wikipedia urls\n",
    "existing_urls = pd.DataFrame({'conference': ['SEC', 'ACC', 'B1G', 'PAC12', 'BIG12', 'AAC', 'MWC', 'MAC', 'CUSA', 'SBC', 'SWC', 'BIG8', 'BIGEAST', 'IVY', 'PCC', 'BORDER', 'MVC', 'SKYLINE', 'WAC'],\n",
    "                          'wiki_link': [SEC, ACC, B1G, PAC12, BIG12, AAC, MWC, MAC, CUSA, SBC, SWC, BIG8, BIGEAST, IVY, PCC, BORDER, MVC, SKYLINE, WAC]})\n",
    "\n",
    "# add the conf_df to the existing_urls dataframe\n",
    "conf_df = pd.concat([conf_df, existing_urls], ignore_index=True)\n",
    "\n",
    "# drop any rows that are duplicates in the wiki_link column\n",
    "conf_df.drop_duplicates(subset=['wiki_link'], keep='first', inplace=True)\n",
    "\n",
    "# sort alphabetically\n",
    "conf_df.sort_values(by=['conference'], inplace=True)\n",
    "\n",
    "conf_df.head(15)\n",
    "\n",
    "len(conf_df)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_df.tail(25)\n",
    "\n",
    "# Save as csv for manual inspection\n",
    "conf_df.to_csv('../TEMP/conference_wiki_links.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Put the URLs into a list and check them for status codes\n",
    "urls = [SEC, ACC, B1G, PAC12, BIG12, AAC, MWC, MAC, CUSA, SBC, SWC, WAC, BIG8, BIGEAST, IVY, PCC, BORDER, MVC, SKYLINE, WAC]\n",
    "\n",
    "# put the list of urls into a for loop to check the status code\n",
    "for url in urls:\n",
    "    response = requests.get(url)\n",
    "    print(f\"{url} status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAC - Mid American Conference\n",
    "\n",
    "# Use beautiful soup to parse the HTML and extract tables\n",
    "response = requests.get(MAC)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "tables = soup.find_all('table', class_='wikitable sortable')\n",
    "\n",
    "# read tables into pandas\n",
    "current = pd.read_html(str(tables[0]))[0]\n",
    "\n",
    "# Manually create the former conference members dataframe\n",
    "# Insitution, Location, Founded, Joined, Left, Nickname\n",
    "\n",
    "# Create the empty dataframe\n",
    "MAC = pd.DataFrame(columns=['Institution', 'Nickname', 'Location', 'Founded', \n",
    "                            'Joined', 'Left', 'Enrollment', 'Conference'])\n",
    "\n",
    "# New dataframe of former members\n",
    "former = pd.DataFrame({'Institution': ['Butler University', 'University of Cincinnati', 'Marshall University', 'Marshall University', 'Wayne State University', 'Western Reserve University'],\n",
    "                          'Location': ['Indianapolis, IN', 'Cincinnati, OH', 'Huntington, WV', 'Huntington, WV', 'Detroit, MI', 'Cleveland, OH'],\n",
    "                            'Founded': [1855, 1819, 1837, 1837, 1868, 1826],\n",
    "                            'Joined': [1946, 1946, 1954, 1997, 1946, 1946],\n",
    "                            'Left': [1950, 1953, 1969, 2005, 1947, 1955],\n",
    "                            'Nickname': ['Bulldogs', 'Bearcats', 'Thundering Herd', 'Thundering Herd', 'Tartars', 'Red Cats']})\n",
    "\n",
    "# Clean the current members dataframe\n",
    "# Rename the column headers\n",
    "col_names = ['Institution', 'Location', 'Founded', 'Joined', 'Type', 'Enrollment',\n",
    "             'Endowment', 'Nickname', 'Colors', 'drop']\n",
    "current.columns = col_names\n",
    "# Drop row with West Division in the Insitution column\n",
    "current = current[current.Institution != 'West Division']\n",
    "# Drop the Northern Illinois row that has errors - will recreate later\n",
    "current = current[current.Institution != 'Northern Illinois University']\n",
    "\n",
    "# Rename University at Buffalo to University of Buffalo\n",
    "current.Institution = current.Institution.replace('University at Buffalo', 'University of Buffalo')\n",
    "\n",
    "# Rename Miamai University to Miami (OH)\n",
    "current.Institution = current.Institution.replace('Miami University', 'Miami (OH)')\n",
    "\n",
    "# # Create new rows\n",
    "new_row1 = {'Institution': 'Northern Illinois University', 'Location': 'DeKalb, IL', 'Founded': 1895, 'Joined': 1997, 'Type': 'Public', 'Enrollment': 19600, 'Endowment': 100000000, 'Nickname': 'Huskies', 'Colors': 'Cardinal and Black', 'drop': np.nan}\n",
    "new_row2 = {'Institution': 'Northern Illinois University', 'Location': 'DeKalb, IL', 'Founded': 1895, 'Joined': 1975, 'Left': 1986, 'Type': 'Public', 'Enrollment': 19600, 'Endowment': 100000000, 'Nickname': 'Huskies', 'Colors': 'Cardinal and Black', 'drop': np.nan}\n",
    "# add rows to the dataframe\n",
    "former = former.append(new_row1, ignore_index=True)\n",
    "former = former.append(new_row2, ignore_index=True)\n",
    "\n",
    "# Combine the current and former dataframes into one\n",
    "MAC = pd.concat([current, former], ignore_index=True)\n",
    "\n",
    "# Add the conference column\n",
    "MAC['Conference'] = 'Mid-American Conference'\n",
    "\n",
    "# Keep only the columns we want\n",
    "MAC = MAC[['Institution', 'Nickname', 'Location', 'Founded', \n",
    "           'Joined', 'Left', 'Enrollment', 'Conference']]\n",
    "\n",
    "current \n",
    "\n",
    "former\n",
    "\n",
    "# Save the dataframe to a csv file\n",
    "MAC.to_csv('..\\TEMP\\conference_data\\MAC.csv', index=False)\n",
    "\n",
    "MAC\n",
    "# Create dataframe of current members\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Working - Output aved in directory: conference_data\n",
    "\n",
    "\n",
    "# Extract and clean SEC data\n",
    "SEC_TABLES = pd.read_html(SEC)\n",
    "current = SEC_TABLES[2]\n",
    "future = SEC_TABLES[3].head()\n",
    "\n",
    "# Drop Columns and standardized names\n",
    "# Keep Institution, Nickname, Location, Founded, Joined, Enrollment\n",
    "\n",
    "# Clean the current membership table\n",
    "\n",
    "# Flatten multi-level headers\n",
    "current.columns = [' '.join(col).strip() for col in current.columns.values]\n",
    "\n",
    "# As a demo, we will now drop the columns that aren't part of the standardized dataframe\n",
    "standard_columns = ['Institution East Division', 'Nickname East Division', 'Location East Division', \n",
    "                    'Founded East Division', 'Joined East Division', 'Enrollment East Division']\n",
    "current = current[standard_columns]\n",
    "\n",
    "# Renaming for standardization\n",
    "rename_map = {\n",
    "    'Institution East Division': 'Institution',\n",
    "    'Nickname East Division': 'Nickname',\n",
    "    'Location East Division': 'Location',\n",
    "    'Founded East Division': 'Founded',\n",
    "    'Joined East Division': 'Joined',\n",
    "    'Enrollment East Division': 'Enrollment'\n",
    "}\n",
    "\n",
    "# Rename columns\n",
    "current = current.rename(columns=rename_map)\n",
    "\n",
    "# keep_col = ['Institution', 'Nickname', 'Location', 'Founded', 'Joined', 'Enrollment']\n",
    "# current = current[keep_col]\n",
    "\n",
    "\n",
    "keep_col_2 = ['Institution', 'Nickname', 'Location', 'Founded', 'Join Date', 'Enrollment']\n",
    "future = future[keep_col_2]\n",
    "\n",
    "# Rename Join Date to Joined\n",
    "future = future.rename(columns={'Join Date': 'Joined'})\n",
    "\n",
    "# Create empty stadard dataframe\n",
    "SEC = pd.DataFrame(columns=['Institution', 'Nickname', 'Location', 'Founded', \n",
    "                            'Joined', 'Left', 'Enrollment', 'Conference'])\n",
    "\n",
    "# combine the two dataframes into the new standard dataframe\n",
    "SEC = SEC.append(current)\n",
    "\n",
    "# add the future dataframe to the standard dataframe\n",
    "SEC = SEC.append(future)\n",
    "\n",
    "# Drop the row that says West Division\n",
    "SEC = SEC[SEC['Institution'] != 'West Division']\n",
    "\n",
    "# Add SEC to the Conference Column\n",
    "SEC['Conference'] = 'SEC'\n",
    "\n",
    "# Clean Enrollment Column\n",
    "SEC['Enrollment'] = SEC['Enrollment'].str.replace(',', '') # Remove commas\n",
    "SEC['Enrollment'] = SEC['Enrollment'].str.replace('\\[.*\\]', '') # Remove references\n",
    "\n",
    "# Fill na values with 0\n",
    "SEC['Enrollment'] = SEC['Enrollment'].fillna(0)\n",
    "# Store as integer\n",
    "SEC['Enrollment'] = SEC['Enrollment'].astype(int)\n",
    "\n",
    "\n",
    "SEC.head(20)\n",
    "\n",
    "\n",
    "# Save output to csv\n",
    "SEC.to_csv('..\\TEMP\\conference_data\\SEC.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "SEC\n",
    "\n",
    "\n",
    "# # future.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract and Clean ACC Data\n",
    "\n",
    "ACC_TABLES = pd.read_html(ACC)\n",
    "current = ACC_TABLES[1]\n",
    "future = ACC_TABLES[2] # Joining to Joined\n",
    "former = ACC_TABLES[3] # \n",
    "\n",
    "# Rename future Joining to Joined\n",
    "future = future.rename(columns={'Joining': 'Joined'})\n",
    "# Remove citation numbers from Enrollment\n",
    "future['Enrollment'] = future['Enrollment'].str.replace(r\"\\[.*\\]\", \"\")\n",
    "\n",
    "\n",
    "# Clean up the Joined Column with regex to remove the citation numbers\n",
    "current['Joined'] = current['Joined'].str.replace(r\"\\[.*\\]\", \"\")\n",
    "\n",
    "# Drop Columns and standardized names \n",
    "# Standard Table:  Institution, Nickname, Location, Founded, Joined, Left, Enrollment, Conference\n",
    "# Combine into single dataframe that includes current, future, and former\n",
    "\n",
    "keep_cols = ['Institution', 'Nickname', 'Location', 'Founded', 'Joined', 'Left', 'Enrollment']\n",
    "\n",
    "ACC = pd.DataFrame(columns=keep_cols)\n",
    "\n",
    "# Concatenate the three dataframes\n",
    "ACC = ACC.append(current)\n",
    "ACC = ACC.append(future)\n",
    "ACC = ACC.append(former)\n",
    "\n",
    "# Keep only the columns in list\n",
    "ACC = ACC[keep_cols]\n",
    "\n",
    "# Clean up Enrollment column\n",
    "ACC['Enrollment'] = ACC['Enrollment'].str.replace(r\"\\[.*\\]\", \"\")\n",
    "# Remove commas\n",
    "ACC['Enrollment'] = ACC['Enrollment'].str.replace(',', '')\n",
    "# Make sure it is numeric\n",
    "ACC['Enrollment'] = pd.to_numeric(ACC['Enrollment'])\n",
    "# Fill NaN with 0\n",
    "ACC['Enrollment'] = ACC['Enrollment'].fillna(0)\n",
    "# store as int\n",
    "ACC['Enrollment'] = ACC['Enrollment'].astype(int)\n",
    "\n",
    "# Rename Miami to Miami (FL)\n",
    "ACC['Institution'] = ACC['Institution'].replace('University of Miami', 'Miami (FL)')\n",
    "# Rename to Virginia Tech\n",
    "ACC['Institution'] = ACC['Institution'].replace('Virginia Polytechnic Institute and State University', 'Virginia Tech')\n",
    "# Rename Maryland to University of Maryland\n",
    "ACC['Institution'] = ACC['Institution'].replace('University of Maryland, College Park', 'University of Maryland')\n",
    "# Rename SOuthern Methodist University to SMU\n",
    "ACC['Institution'] = ACC['Institution'].replace('Southern Methodist University', 'SMU')\n",
    "# University of North Carolina at Chapel Hill to University of North Carolina\n",
    "ACC['Institution'] = ACC['Institution'].replace('University of North Carolina at Chapel Hill', 'University of North Carolina')\n",
    "# Georgia Institute of Technology to Georgia Tech\n",
    "ACC['Institution'] = ACC['Institution'].replace('Georgia Institute of Technology', 'Georgia Tech')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Add the Conference column\n",
    "ACC['Conference'] = 'ACC'\n",
    "\n",
    "\n",
    "## Save output to csv\n",
    "ACC.to_csv('..\\TEMP\\conference_data\\ACC.csv', index=False)\n",
    "# ACC.info()\n",
    "\n",
    "future\n",
    "# current\n",
    "# former\n",
    "\n",
    "ACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BIG 12\n",
    "\n",
    "BIG12_TABLES = pd.read_html(BIG12)\n",
    "\n",
    "current = BIG12_TABLES[1]\n",
    "future = BIG12_TABLES[2]\n",
    "former = BIG12_TABLES[4]\n",
    "\n",
    "# Remover citation numbers from Left column in former\n",
    "former['Left'] = former['Left'].str.replace(r\"\\[.*\\]\", \"\")\n",
    "# Remove citation numbers from Enrollment in all three\n",
    "current['Enrollment'] = current['Enrollment'].str.replace(r\"\\[.*\\]\", \"\")\n",
    "future['Enrollment'] = future['Enrollment'].str.replace(r\"\\[.*\\]\", \"\")\n",
    "# former['Enrollment'] = former['Enrollment'].str.replace(r\"\\[.*\\]\", \"\")\n",
    "\n",
    "# Create a standard dataframe\n",
    "BIG12 = pd.DataFrame(columns=['Institution', 'Nickname', 'Location', 'Founded', 'Joined', 'Left', 'Enrollment', 'Conference'])\n",
    "\n",
    "# Concatenate the three dataframes\n",
    "BIG12 = BIG12.append(current)\n",
    "BIG12 = BIG12.append(future)\n",
    "BIG12 = BIG12.append(former)\n",
    "\n",
    "# Add the conference name to the Conference column\n",
    "BIG12['Conference'] = 'Big 12'\n",
    "# Save output to csv\n",
    "BIG12.to_csv('..\\TEMP\\conference_data\\BIG12.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mountain West Conference\n",
    "\n",
    "\n",
    "MWC_TABLES = pd.read_html(MWC)\n",
    "current = MWC_TABLES[1]\n",
    "former = MWC_TABLES[3]\n",
    "\n",
    "# Create the Standard Dataframe\n",
    "MWC = pd.DataFrame(columns=['Institution', 'Nickname', 'Location', 'Founded', 'Joined', 'Left', 'Enrollment', 'Conference'])\n",
    "\n",
    "# Combine the two dataframes into standard dataframe with the keep_cols\n",
    "keep_cols = ['Institution', 'Nickname', 'Location', 'Founded', 'Joined', 'Left', 'Enrollment', 'Conference']\n",
    "\n",
    "MWC = MWC.append(current)\n",
    "MWC = MWC.append(former)\n",
    "# Add conference name to Conference column\n",
    "MWC['Conference'] = 'Mountain West Conference'\n",
    "# keep only the columns in the keep_cols list\n",
    "MWC = MWC[keep_cols]\n",
    "\n",
    "# Save to csv\n",
    "MWC.to_csv('..\\TEMP\\conference_data\\MWC.csv', index=False)\n",
    "\n",
    "\n",
    "MWC\n",
    "# current\n",
    "# # former"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conference USA\n",
    "\n",
    "CUSA_TABLES = pd.read_html(CUSA)\n",
    "current = CUSA_TABLES[1]\n",
    "future = CUSA_TABLES[3] \n",
    "former = CUSA_TABLES[4]\n",
    "\n",
    "# Create the Standard Dataframe\n",
    "CUSA = pd.DataFrame(columns=['Institution', 'Nickname', 'Location', 'Founded', 'Joined', 'Left', 'Enrollment', 'Conference'])\n",
    "\n",
    "# Combine The three dataframes into the standard dataframe\n",
    "CUSA = CUSA.append(current)\n",
    "CUSA = CUSA.append(future)\n",
    "CUSA = CUSA.append(former)\n",
    "\n",
    "# Remove citation numbers from Joined and Left columns\n",
    "CUSA['Joined'] = CUSA['Joined'].str.replace(r\"\\[.*\\]\", \"\")\n",
    "CUSA['Enrollment'] = CUSA['Enrollment'].str.replace(r\"\\[.*\\]\", \"\")\n",
    "# Remove commas\n",
    "CUSA['Enrollment'] = CUSA['Enrollment'].str.replace(',', '')\n",
    "# Fill NaN with 0\n",
    "CUSA['Enrollment'] = CUSA['Enrollment'].fillna(0)\n",
    "# store as int\n",
    "CUSA['Enrollment'] = CUSA['Enrollment'].astype(int)\n",
    "\n",
    "# Keep only the columns in the keep_cols list\n",
    "keep_cols = ['Institution', 'Nickname', 'Location', 'Founded', 'Joined', 'Left', 'Enrollment', 'Conference']\n",
    "\n",
    "CUSA = CUSA[keep_cols]\n",
    "\n",
    "# Add conference name to Conference column\n",
    "CUSA['Conference'] = 'Conference USA'\n",
    "\n",
    "# Save to csv\n",
    "CUSA.to_csv('..\\TEMP\\conference_data\\CUSA.csv', index=False)\n",
    "\n",
    "CUSA\n",
    "\n",
    "\n",
    "# current\n",
    "# former"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sun Belt Conference\n",
    "\n",
    "SBC_TABLES = pd.read_html(SBC)\n",
    "current = SBC_TABLES[1]\n",
    "future = SBC_TABLES[2]\n",
    "former = SBC_TABLES[3]\n",
    "\n",
    "# Create the Standard Dataframe\n",
    "SBC = pd.DataFrame(columns=['Institution', 'Nickname', 'Location', 'Founded', 'Joined', 'Left', 'Enrollment', 'Conference'])\n",
    "\n",
    "# Combine The three dataframes into the standard dataframe\n",
    "SBC = SBC.append(current)\n",
    "SBC = SBC.append(future)\n",
    "SBC = SBC.append(former)\n",
    "\n",
    "# Remove citation numbers from Joined and Left columns\n",
    "# Make sure all columns are strings\n",
    "SBC['Founded'] = SBC['Founded'].astype(str)\n",
    "SBC['Joined'] = SBC['Joined'].astype(str)\n",
    "SBC['Enrollment'] = SBC['Enrollment'].astype(str)\n",
    "SBC['Joined'] = SBC['Joined'].str.replace(r\"\\[.*\\]\", \"\")\n",
    "SBC['Enrollment'] = SBC['Enrollment'].str.replace(r\"\\[.*\\]\", \"\")\n",
    "SBC['Left'] = SBC['Left'].str.replace(r\"\\[.*\\]\", \"\")\n",
    "\n",
    "# Keep only the columns in the keep_cols list\n",
    "keep_cols = ['Institution', 'Nickname', 'Location', 'Founded', 'Joined', 'Left', 'Enrollment', 'Conference']\n",
    "\n",
    "# Add conference name to Conference column\n",
    "SBC['Conference'] = 'Sun Belt Conference'\n",
    "\n",
    "# Drop the row that says Public\n",
    "SBC = SBC[SBC['Institution'] != 'Public']\n",
    "\n",
    "# Take care of nan values in the Joined column\n",
    "# SBC['Joined'] = SBC['Joined'].fillna(0)\n",
    "\n",
    "# Make sure Joined, Founded and left are an int\n",
    "#Need to convert to float first to get rid of the decimal\n",
    "SBC['Joined'] = SBC['Joined'].astype(float)\n",
    "SBC['Joined'] = SBC['Joined'].fillna(0)\n",
    "SBC['Joined'] = SBC['Joined'].astype(int)\n",
    "\n",
    "SBC['Founded'] = SBC['Founded'].astype(float)\n",
    "SBC['Founded'] = SBC['Founded'].fillna(0)\n",
    "SBC['Founded'] = SBC['Founded'].astype(int)\n",
    "\n",
    "SBC['Left'] = SBC['Left'].astype(float)\n",
    "SBC['Left'] = SBC['Left'].fillna(0)\n",
    "SBC['Left'] = SBC['Left'].astype(int)\n",
    "\n",
    "\n",
    "# Save to csv\n",
    "SBC.to_csv('..\\TEMP\\conference_data\\SBC.csv', index=False)\n",
    "\n",
    "# current\n",
    "future\n",
    "# former\n",
    "SBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Southwest Conference (Defunct)\n",
    "\n",
    "SWC_TABLES = pd.read_html(SWC)\n",
    "temp = SWC_TABLES[2]\n",
    "final = SWC_TABLES[3]\n",
    "# Rename Academic Year of Departure\tto Left\n",
    "final = final.rename(columns={'Academic Year of Departure': 'Left'})\n",
    "temp = temp.rename(columns={'Academic Year of Departure': 'Left'})\n",
    "# Remane Team to Institution\n",
    "temp = temp.rename(columns={'Team': 'Institution'})\n",
    "final = final.rename(columns={'Team': 'Institution'})\n",
    "\n",
    "# make standard dataframe\n",
    "SWC = pd.DataFrame(columns=['Institution', 'Nickname', 'Location', 'Founded', 'Joined', 'Left', 'Enrollment', 'Conference'])\n",
    "\n",
    "# Combine the two dataframes into the standard dataframe\n",
    "SWC = SWC.append(temp)\n",
    "SWC = SWC.append(final)\n",
    "\n",
    "# Keep only the columns in the keep_cols list\n",
    "keep_cols = ['Institution', 'Nickname', 'Location', 'Founded', 'Joined', 'Left', 'Enrollment', 'Conference']\n",
    "\n",
    "SWC = SWC[keep_cols]\n",
    "\n",
    "# Add conference name to Conference column\n",
    "SWC['Conference'] = 'Southwest Conference'\n",
    "\n",
    "# Manually add the Joined date to schools \n",
    "SWC.loc[SWC['Institution'] == 'Arkansas', 'Joined'] = 1915\n",
    "SWC.loc[SWC['Institution'] == 'Baylor', 'Joined'] = 1915\n",
    "SWC.loc[SWC['Institution'] == 'Houston', 'Joined'] = 1976\n",
    "SWC.loc[SWC['Institution'] == 'Rice', 'Joined'] = 1915\n",
    "SWC.loc[SWC['Institution'] == 'SMU', 'Joined'] = 1918\n",
    "SWC.loc[SWC['Institution'] == 'TCU', 'Joined'] = 1923\n",
    "SWC.loc[SWC['Institution'] == 'Texas', 'Joined'] = 1915\n",
    "SWC.loc[SWC['Institution'] == 'Texas A&M', 'Joined'] = 1915\n",
    "SWC.loc[SWC['Institution'] == 'Texas Tech', 'Joined'] = 1956\n",
    "SWC.loc[SWC['Institution'] == 'Southwestern', 'Joined'] = 1915\n",
    "SWC.loc[SWC['Institution'] == 'Phillips', 'Joined'] = 1920\n",
    "SWC.loc[SWC['Institution'] == 'Oklahoma', 'Joined'] = 1915\n",
    "SWC.loc[SWC['Institution'] == 'Oklahoma A&M', 'Joined'] = 1915\n",
    "\n",
    "\n",
    "# Save to csv\n",
    "SWC.to_csv('..\\TEMP\\conference_data\\SWC.csv', index=False)\n",
    "SWC\n",
    "# # temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Western_Athletic_Conference\n",
    "\n",
    "WAC_TABLES = pd.read_html(WAC)\n",
    "current = WAC_TABLES[1]\n",
    "former = WAC_TABLES[2]\n",
    "\n",
    "# rename columns - First Year to Joined, Last Year to Left\n",
    "current = current.rename(columns={'First Year': 'Joined', 'Last Year': 'Left'})\n",
    "\n",
    "# Fix Team Name - Split them into Institution and Nickname\n",
    "\n",
    "def split_team_name(team_name):\n",
    "    words = team_name.split()\n",
    "    \n",
    "    # Rule 1: Two-word teams\n",
    "    if len(words) == 2:\n",
    "        return words[0], words[1]\n",
    "    \n",
    "    # Rule 2: Three-word teams with 'State'\n",
    "    if len(words) == 3 and words[1] == 'State':\n",
    "        return ' '.join(words[:2]), words[2]\n",
    "    \n",
    "    # Rule 3: Three-word teams without 'State'\n",
    "    if len(words) == 3 and words[1] != 'State':\n",
    "        return words[0], ' '.join(words[1:])\n",
    "    \n",
    "    # Rule 4: Four-word teams with 'New Mexico'\n",
    "    if len(words) == 4 and ' '.join(words[:2]) == 'New Mexico':\n",
    "        return ' '.join(words[:2]), ' '.join(words[2:])\n",
    "    \n",
    "    # Rule 5: Four-word teams\n",
    "    if len(words) == 4:\n",
    "        return ' '.join(words[:3]), words[3]\n",
    "    \n",
    "    # Rule 6: One-word teams\n",
    "    if len(words) == 1:\n",
    "        return team_name, \"\"  # manually fill in the nickname later\n",
    "\n",
    "    return team_name, \"\"  # default fallback\n",
    "\n",
    "# Apply the split_team_name function to the Team column\n",
    "current[['Institution', 'Nickname']] = current['Team'].apply(split_team_name).apply(pd.Series)                   \n",
    "\n",
    "# Create the Standard Dataframe\n",
    "WAC = pd.DataFrame(columns=['Institution', 'Nickname', 'Location', 'Founded', 'Joined', 'Left', 'Enrollment', 'Conference'])\n",
    "\n",
    "# Combine The three dataframes into the standard dataframe\n",
    "WAC = WAC.append(current)\n",
    "WAC = WAC.append(former)\n",
    "\n",
    "## Keep only the columns in the keep_cols list\n",
    "keep_cols = ['Institution', 'Nickname', 'Location', 'Founded', 'Joined', 'Left', 'Enrollment', 'Conference']\n",
    "\n",
    "WAC = WAC[keep_cols]\n",
    "\n",
    "# Add conference name to Conference column\n",
    "WAC['Conference'] = 'Western Athletic Conference'\n",
    "\n",
    "# Manually clean the Same Houston State Nickname and Institution\n",
    "WAC.loc[WAC['Institution'] == 'Sam', 'Nickname'] = 'Bearkats'\n",
    "WAC.loc[WAC['Institution'] == 'Sam', 'Institution'] = 'Sam Houston State'\n",
    "WAC.loc[WAC['Institution'] == 'Arizona State Sun', 'Institution'] = 'Arizona State'\n",
    "WAC.loc[WAC['Institution'] == 'Arizona State', 'Nickname'] = 'Sun Devils'\n",
    "\n",
    "# Manually clean the New Mexico State Nickname and Institution\n",
    "WAC.loc[WAC['Institution'] == 'New Mexico', 'Nickname'] = 'Aggies'\n",
    "WAC.loc[WAC['Institution'] == 'New Mexico', 'Institution'] = 'New Mexico State'\n",
    "\n",
    "# manually clean the New Mexico Nickname and Institution\n",
    "WAC.loc[WAC['Institution'] == 'New', 'Nickname'] = 'Lobos'\n",
    "WAC.loc[WAC['Institution'] == 'New', 'Institution'] = 'New Mexico'\n",
    "\n",
    "# Manually Fix Air Force\n",
    "WAC.loc[WAC['Institution'] == 'Air', 'Nickname'] = 'Falcons'\n",
    "WAC.loc[WAC['Institution'] == 'Air', 'Institution'] = 'Air Force'\n",
    "\n",
    "# Save to csv\n",
    "WAC.to_csv('..\\TEMP\\conference_data\\WAC.csv', index=False)\n",
    "current\n",
    "WAC\n",
    "# print(current['Team'].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Big 8 Conference - Defunct\n",
    "\n",
    "BIG8_TABLES = pd.read_html(BIG8)\n",
    "\n",
    "final = BIG8_TABLES[1]\n",
    "other = BIG8_TABLES[2]\n",
    "\n",
    "# Add 1996 to the Left column of the final dataframe\n",
    "final['Left'] = 1996\n",
    "\n",
    "# Joined and Left dates for the other dataframe\n",
    "# Drake - Joined 1908, Left 1928\n",
    "# Grinnell - Joined 1918, Left 1928\n",
    "# University of Iowa - Joined 1907, Left 1911\n",
    "# Washington University - Joined 1907, Left 1928\n",
    "\n",
    "# Apply those dates to the other dataframe\n",
    "other.loc[other['Institution'] == 'Drake University', 'Joined'] = 1908\n",
    "other.loc[other['Institution'] == 'Drake University', 'Left'] = 1928\n",
    "other.loc[other['Institution'] == 'Grinnell College', 'Joined'] = 1918\n",
    "other.loc[other['Institution'] == 'Grinnell College', 'Left'] = 1928\n",
    "other.loc[other['Institution'] == 'University of Iowa', 'Joined'] = 1907\n",
    "other.loc[other['Institution'] == 'University of Iowa', 'Left'] = 1911\n",
    "other.loc[other['Institution'] == 'Washington University in St. Louis', 'Joined'] = 1907\n",
    "other.loc[other['Institution'] == 'Washington University in St. Louis', 'Left'] = 1928\n",
    "other.loc[other['Institution'] == 'Washington University in St. Louis', 'Nickname'] = 'Bears'\n",
    "\n",
    "# Make standard dataframe\n",
    "BIG8 = pd.DataFrame(columns=['Institution', 'Nickname', 'Location', 'Founded', 'Joined', 'Left', 'Enrollment', 'Conference'])\n",
    "\n",
    "# Combine the two dataframes into the standard dataframe\n",
    "BIG8 = BIG8.append(final)\n",
    "BIG8 = BIG8.append(other)\n",
    "\n",
    "# Keep only the columns in the keep_cols list\n",
    "keep_cols = ['Institution', 'Nickname', 'Location', 'Founded', 'Joined', 'Left', 'Enrollment', 'Conference']\n",
    "\n",
    "BIG8 = BIG8[keep_cols]\n",
    "\n",
    "# Add conference name to Conference column\n",
    "BIG8['Conference'] = 'Big 8 Conference'\n",
    "\n",
    "# Remove citation numbers from Enrollment. Make sure it is a string first\n",
    "# Output a int\n",
    "BIG8['Enrollment'] = BIG8['Enrollment'].astype(str)\n",
    "BIG8['Enrollment'] = BIG8['Enrollment'].str.replace(r\"\\[.*\\]\", \"\")\n",
    "# Remove commas\n",
    "BIG8['Enrollment'] = BIG8['Enrollment'].str.replace(',', '')\n",
    "BIG8['Enrollment'] = BIG8['Enrollment'].astype(int)\n",
    "\n",
    "\n",
    "# Make sure Joined, Founded and Left are are int type\n",
    "BIG8['Joined'] = BIG8['Joined'].astype(float)\n",
    "BIG8['Joined'] = BIG8['Joined'].fillna(0)\n",
    "BIG8['Joined'] = BIG8['Joined'].astype(int)\n",
    "\n",
    "BIG8['Founded'] = BIG8['Founded'].astype(float)\n",
    "BIG8['Founded'] = BIG8['Founded'].fillna(0)\n",
    "BIG8['Founded'] = BIG8['Founded'].astype(int)\n",
    "\n",
    "BIG8['Left'] = BIG8['Left'].astype(float)\n",
    "BIG8['Left'] = BIG8['Left'].fillna(0)\n",
    "BIG8['Left'] = BIG8['Left'].astype(int)\n",
    "\n",
    "# Save to csv\n",
    "BIG8.to_csv('..\\TEMP\\conference_data\\BIG8.csv', index=False)\n",
    "\n",
    "BIG8\n",
    "\n",
    "# final\n",
    "# other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ivy League\n",
    "\n",
    "IVY_TABLES = pd.read_html(IVY)\n",
    "table1 = IVY_TABLES[1]\n",
    "table2 = IVY_TABLES[2]\n",
    "\n",
    "# Create the Standard Dataframe\n",
    "IVY = pd.DataFrame(columns=['Institution', 'Nickname', 'Location', 'Founded', 'Joined', 'Left', 'Enrollment', 'Conference'])\n",
    "\n",
    "\n",
    "# Merge table on Institution\n",
    "table1.merge(table2, on='Institution', how='outer')\n",
    "\n",
    "# Rename columns - Undergraduates to Enrollment\n",
    "table1 = table1.rename(columns={'Undergraduates': 'Enrollment'})\n",
    "# Add Joined date - 1956 - offical incorporation of the Ivy League\n",
    "table1['Joined'] = 1954\n",
    "# Add Left date - 1981 - Ivy League Drops out of FBS Football\n",
    "table1['Left'] = 1981\n",
    "\n",
    "# Create the Standard Dataframe\n",
    "IVY = pd.DataFrame(columns=['Institution', 'Nickname', 'Location', 'Founded', 'Joined', 'Left', 'Enrollment', 'Conference'])\n",
    "\n",
    "# add the table1 to the standard dataframe\n",
    "IVY = IVY.append(table1)\n",
    "\n",
    "# Save just the keep_cols\n",
    "keep_cols = ['Institution', 'Nickname', 'Location', 'Founded', 'Joined', 'Left', 'Enrollment', 'Conference']\n",
    "\n",
    "IVY = IVY[keep_cols]\n",
    "\n",
    "# Add conference name to Conference column\n",
    "IVY['Conference'] = 'Ivy League'\n",
    "\n",
    "founded_list = [1642,1702,1747,1754,1755,1765,1768,1868]\n",
    "IVY['Founded'] = founded_list\n",
    "\n",
    "# Save to csv\n",
    "IVY.to_csv('..\\TEMP\\conference_data\\IVY.csv', index=False)\n",
    "\n",
    "IVY\n",
    "# table1\n",
    "# # table2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pacific Coast Conference\n",
    "\n",
    "# University of California, Berkeley (1915–1959)\n",
    "# University of Oregon (1915–1959)\n",
    "# Oregon State College (1915–1959)\n",
    "# University of Washington (1915–1959)\n",
    "# Washington State College (1917–1959)\n",
    "# Stanford University (1918–1959)\n",
    "# University of Idaho (1922–1959)\n",
    "# University of Southern California (1922–1959, suspended in 1924)\n",
    "# University of Montana (1924–1950)\n",
    "# University of California, Los Angeles (1928–1959)\n",
    "\n",
    "#Create the Standard Dataframe\n",
    "PCC = pd.DataFrame(columns=['Institution', 'Nickname', 'Location', 'Founded', 'Joined', 'Left', 'Enrollment', 'Conference'])\n",
    "\n",
    "# Add the schools to the dataframe\n",
    "PCC.loc[0] = ['University of California, Berkeley', 'Golden Bears', 'Berkeley, California', 1868, 1915, 1959, 31000, 'Pacific Coast Conference']\n",
    "PCC.loc[1] = ['University of Oregon', 'Ducks', 'Eugene, Oregon', 1876, 1915, 1959, 22000, 'Pacific Coast Conference']\n",
    "PCC.loc[2] = ['Oregon State College', 'Beavers', 'Corvallis, Oregon', 1868, 1915, 1959, 31000, 'Pacific Coast Conference']\n",
    "PCC.loc[3] = ['University of Washington', 'Huskies', 'Seattle, Washington', 1861, 1915, 1959, 31000, 'Pacific Coast Conference']\n",
    "PCC.loc[4] = ['Washington State College', 'Cougars', 'Pullman, Washington', 1890, 1917, 1959, 31000, 'Pacific Coast Conference']\n",
    "PCC.loc[5] = ['Stanford University', 'Cardinal', 'Stanford, California', 1891, 1918, 1959, 31000, 'Pacific Coast Conference']\n",
    "PCC.loc[6] = ['University of Idaho', 'Vandals', 'Moscow, Idaho', 1889, 1922, 1959, 31000, 'Pacific Coast Conference']\n",
    "PCC.loc[7] = ['University of Southern California', 'Trojans', 'Los Angeles, California', 1880, 1922, 1959, 31000, 'Pacific Coast Conference']\n",
    "PCC.loc[8] = ['University of Montana', 'Grizzlies', 'Missoula, Montana', 1893, 1924, 1950, 31000, 'Pacific Coast Conference']\n",
    "PCC.loc[9] = ['University of California, Los Angeles', 'Bruins', 'Los Angeles, California', 1919, 1928, 1959, 31000, 'Pacific Coast Conference']\n",
    "\n",
    "# Addd the Conference name to the Conference column\n",
    "PCC['Conference'] = 'Pacific Coast Conference'\n",
    "\n",
    "## Save to csv\n",
    "PCC.to_csv('..\\TEMP\\conference_data\\PCC.csv', index=False)\n",
    "\n",
    "# PCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Border Conference\n",
    "\n",
    "BORDER_TABLES = pd.read_html(BORDER)\n",
    "table1 = BORDER_TABLES[1]\n",
    "table2 = BORDER_TABLES[2]\n",
    "\n",
    "# Create the Standard Dataframe\n",
    "BORDER = pd.DataFrame(columns=['Institution', 'Nickname', 'Location', 'Founded', 'Joined', 'Left', 'Enrollment', 'Conference'])\n",
    "\n",
    "# Add the data to the standard dataframe\n",
    "BORDER = BORDER.append(table1)\n",
    "BORDER = BORDER.append(table2)\n",
    "\n",
    "# Clean the Joined Column of citation numbers\n",
    "BORDER['Joined'] = BORDER['Joined'].str.replace(r\"\\[.*\\]\", \"\")\n",
    "# Clean the Institution Column of citation numbers\n",
    "BORDER['Institution'] = BORDER['Institution'].str.replace(r\"\\[.*\\]\", \"\")\n",
    "# Overwrite Texas Tech University Left date with 1957\n",
    "BORDER.loc[BORDER['Institution'] == 'Texas Tech University', 'Left'] = 1957\n",
    "\n",
    "\n",
    "\n",
    "BORDER['Conference'] = 'Border Conference'\n",
    "\n",
    "# Save to csv\n",
    "BORDER.to_csv('..\\TEMP\\conference_data\\BORDER.csv', index=False)\n",
    "\n",
    "BORDER\n",
    "# table1\n",
    "# table2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missouri Valley Conference\n",
    "\n",
    "MVC_TABLES = pd.read_html(MVC)\n",
    "current = MVC_TABLES[2] # Sows Current Memebers but it is no longer a Major Conference\n",
    "former = MVC_TABLES[4]\n",
    "\n",
    "# Clean up Institution Column\n",
    "# Remove anything in brackets []\n",
    "former['Institution'] = former['Institution'].str.replace(r\"\\[.*\\]\", \"\")\n",
    "# Clean up Joined Column\n",
    "# Remove anything in brackets []\n",
    "former['Joined'] = former['Joined'].str.replace(r\"\\[.*\\]\", \"\")\n",
    "# Clean Enrollment\n",
    "# Remove anything in brackets []\n",
    "former['Enrollment'] = former['Enrollment'].str.replace(r\"\\[.*\\]\", \"\")\n",
    "\n",
    "\n",
    "# Create a row for each time a school has joined and left\n",
    "\n",
    "# Remove old Creighton and Nebraska rows\n",
    "former = former[former['Institution'] != 'Creighton University']\n",
    "former = former[former['Institution'] != 'Nebraska']\n",
    "# # Creighton University - Joined 1928, Left 1948, Joined 1977, Left 2013\n",
    "# University of Nebraska - Joined 1907, Left 1919, Joined 1921, Left 1928\n",
    "\n",
    "new_row1 = {'Institution': 'Creighton University', 'Nickname': 'Bluejays', 'Location': 'Omaha, Nebraska', 'Founded': 1878, 'Joined': 1928, 'Left': 1948, 'Enrollment': 8000, 'Conference': 'Missouri Valley Conference'}\n",
    "new_row2 = {'Institution': 'Creighton University', 'Nickname': 'Bluejays', 'Location': 'Omaha, Nebraska', 'Founded': 1878, 'Joined': 1977, 'Left': 2013, 'Enrollment': 8000, 'Conference': 'Missouri Valley Conference'}\n",
    "new_row3 = {'Institution': 'University of Nebraska', 'Nickname': 'Cornhuskers', 'Location': 'Lincoln, Nebraska', 'Founded': 1869, 'Joined': 1907, 'Left': 1919, 'Enrollment': 25000, 'Conference': 'Missouri Valley Conference'}\n",
    "new_row4 = {'Institution': 'University of Nebraska', 'Nickname': 'Cornhuskers', 'Location': 'Lincoln, Nebraska', 'Founded': 1869, 'Joined': 1921, 'Left': 1928, 'Enrollment': 25000, 'Conference': 'Missouri Valley Conference'}\n",
    "\n",
    "# Add the new rows to the dataframe\n",
    "former = former.append(new_row1, ignore_index=True)\n",
    "former = former.append(new_row2, ignore_index=True)\n",
    "former = former.append(new_row3, ignore_index=True)\n",
    "former = former.append(new_row4, ignore_index=True)\n",
    "\n",
    "\n",
    "# Nebraska - Joined 1907, Left 1928\n",
    "former.loc[former['Institution'] == 'Nebraska', 'Joined'] = 1907\n",
    "former.loc[former['Institution'] == 'Nebraska', 'Left'] = 1928\n",
    "\n",
    "# Creighton - Joined 1928, Left 1948\n",
    "former.loc[former['Institution'] == 'Creighton', 'Joined'] = 1928\n",
    "former.loc[former['Institution'] == 'Creighton', 'Left'] = 1948\n",
    "\n",
    "# Create a new row for Creighton - Joined 1977, Left 2013 - Call it Creighton 2\n",
    "Creighton_2 = former.loc[former['Institution'] == 'Creighton University 2']\n",
    "# Add Joined and Left dates\n",
    "Creighton_2['Joined'] = 1977\n",
    "Creighton_2['Left'] = 2013\n",
    "# Rename Creighton University 2 to Creighton\n",
    "Creighton_2['Institution'] = 'Creighton'\n",
    "\n",
    "# Add to the former dataframe\n",
    "former = former.append(Creighton_2)\n",
    "\n",
    "\n",
    "\n",
    "# Sort by Institution and Joined\n",
    "MVC = former.sort_values(by=['Institution', 'Joined'])\n",
    "\n",
    "# Add the Conference name to the Conference column\n",
    "MVC['Conference'] = 'Missouri Valley Conference'\n",
    "\n",
    "# Manually Remove the just the last instance of University of nebreska [index 13]\n",
    "MVC = MVC.drop([13])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Save to csv\n",
    "MVC.to_csv('..\\TEMP\\conference_data\\MVC.csv', index=False)\n",
    "\n",
    "# table1 \n",
    "MVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Skyline Conference\n",
    "\n",
    "SKYLINE_TABLES = pd.read_html(SKYLINE)\n",
    "final = SKYLINE_TABLES[1]\n",
    "former = SKYLINE_TABLES[2]\n",
    "\n",
    "# Clean up Joined and left columns - take first 4 digits\n",
    "final['Joined'] = final['Joined'].str[:4]\n",
    "final['Left'] = final['Left'].str[:4]\n",
    "former['Joined'] = former['Joined'].str[:4]\n",
    "former['Left'] = former['Left'].str[:4]\n",
    "\n",
    "\n",
    "# Create the Standard Dataframe\n",
    "SKYLINE = pd.DataFrame(columns=['Institution', 'Nickname', 'Location', 'Founded', 'Joined', 'Left', 'Enrollment', 'Conference'])\n",
    "\n",
    "# Combine The three dataframes into the standard dataframe\n",
    "SKYLINE = SKYLINE.append(final)\n",
    "SKYLINE = SKYLINE.append(former)\n",
    "\n",
    "# Add Conference Name to Conference Column\n",
    "SKYLINE['Conference'] = 'Skyline Conference'\n",
    "\n",
    "# only keep the columns in the keep_cols list\n",
    "keep_cols = ['Institution', 'Nickname', 'Location', 'Founded', 'Joined', 'Left', 'Enrollment', 'Conference']\n",
    "\n",
    "SKYLINE = SKYLINE[keep_cols]\n",
    "# Add Conference Name to Conference Column\n",
    "SKYLINE['Conference'] = 'Skyline Conference'\n",
    "\n",
    "# Clean the Institution Column of citation numbers\n",
    "SKYLINE['Institution'] = SKYLINE['Institution'].str.replace(r\"\\[.*\\]\", \"\")\n",
    "\n",
    "# Clean the Nickname of University of Wyoming\n",
    "SKYLINE.loc[SKYLINE['Institution'] == 'University of Wyoming', 'Nickname'] = 'Cowboys'\n",
    "\n",
    "# Save to csv\n",
    "SKYLINE.to_csv('..\\TEMP\\conference_data\\SKYLINE.csv', index=False)\n",
    "\n",
    "\n",
    "SKYLINE\n",
    "\n",
    "\n",
    "# final\n",
    "# former"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Big 10 Conference\n",
    "\n",
    "# Can't use pandas to read the table because it is a multi-level header\n",
    "# need to use beautiful soup to extract the table\n",
    "\n",
    "# Create a function to extract the tables from the url\n",
    "def extract_table(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    tables = soup.find_all('table')\n",
    "    return tables\n",
    "\n",
    "# Extract the tables from the url\n",
    "tables = extract_table(B1G)\n",
    "\n",
    "# Read them into pandas\n",
    "current = pd.read_html(str(tables[1]))[0]\n",
    "# Clean up table - remove extra header rows\n",
    "current.columns = current.columns.droplevel(1)\n",
    "# Drop Row that is West Division\n",
    "current = current[current['Institution'] != 'West Division']\n",
    "# current\n",
    "# Add a Left coulumn\n",
    "current['Left'] = ''\n",
    "\n",
    "# Create two rows for Michigan to Reflect the two times they left the conference\n",
    "# Drop the University of Michigan row\n",
    "current = current[current['Institution'] != 'University of Michigan']\n",
    "# Create the two new rows - first joined 1896, left 1907, second joined 1917, left never\n",
    "row1 = {'Institution': 'University of Michigan', 'Nickname': 'Wolverines', 'Location': 'Ann Arbor, Michigan', 'Founded': 1817, 'Joined': 1896, 'Left': 1907, 'Enrollment': 45000, 'Conference': 'Big Ten Conference'}\n",
    "row2 = {'Institution': 'University of Michigan', 'Nickname': 'Wolverines', 'Location': 'Ann Arbor, Michigan', 'Founded': 1817, 'Joined': 1917, 'Left': '', 'Enrollment': 45000, 'Conference': 'Big Ten Conference'}\n",
    "\n",
    "# Add the two new rows\n",
    "current = current.append(row1, ignore_index=True)\n",
    "current = current.append(row2, ignore_index=True)\n",
    "\n",
    "\n",
    "# Future Members\n",
    "future = pd.read_html(str(tables[2]))[0]\n",
    "# Rename Join Date to Joined\n",
    "future = future.rename(columns={'Join Date': 'Joined'})\n",
    "\n",
    "# Create the Standard Dataframe\n",
    "B1G = pd.DataFrame(columns=['Institution', 'Nickname', 'Location', 'Founded', 'Joined', 'Left', 'Enrollment', 'Conference'])\n",
    "\n",
    "# Combine The two dataframes into the standard dataframe\n",
    "B1G = B1G.append(current)\n",
    "B1G = B1G.append(future)\n",
    "\n",
    "# Keep only the columns in the keep_cols list\n",
    "keep_cols = ['Institution', 'Nickname', 'Location', 'Founded', 'Joined', 'Left', 'Enrollment', 'Conference']\n",
    "\n",
    "B1G = B1G[keep_cols]\n",
    "\n",
    "# Add conference name to Conference column\n",
    "B1G['Conference'] = 'Big Ten Conference'\n",
    "\n",
    "# Fix Joined Manually\n",
    "# Michigan State University - Joined 1950\n",
    "# Indiana University - Joined 1899\n",
    "# University of Iowa - Joined 1899\n",
    "# Penn State University - Joined 1990\n",
    "\n",
    "B1G.loc[B1G['Institution'] == 'Michigan State University', 'Joined'] = 1950\n",
    "B1G.loc[B1G['Institution'] == 'Indiana University Bloomington', 'Joined'] = 1899\n",
    "B1G.loc[B1G['Institution'] == 'University of Iowa', 'Joined'] = 1899\n",
    "B1G.loc[B1G['Institution'] == 'Pennsylvania State University', 'Joined'] = 1990\n",
    "\n",
    "# Clean Up Names in Institution column\n",
    "replacements = {'University of Illinois Urbana–Champaign': 'Illinois',\n",
    "                'Indiana University Bloomington': 'Indiana',\n",
    "                'The Ohio State University': 'Ohio State',\n",
    "                'Pennsylvania State University': 'Penn State',\n",
    "                'Rutgers University–New Brunswick': 'Rutgers',\n",
    "                'University of Minnesota, Twin Cities': 'Minnesota',\n",
    "                'University of Nebraska–Lincoln': 'Nebraska',\n",
    "                'University of Wisconsin–Madison': 'Wisconsin',\n",
    "                'University of California, Los Angeles': 'UCLA',\n",
    "                'University of Maryland, College Park': 'Maryland',\n",
    "}\n",
    "\n",
    "# Apply replacements to the Institution column\n",
    "B1G['Institution'] = B1G['Institution'].replace(replacements)\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "# Save to csv\n",
    "B1G.to_csv('..\\TEMP\\conference_data\\B1G.csv', index=False)\n",
    "\n",
    "B1G\n",
    "\n",
    "# current\n",
    "# future\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pac 12 Conference\n",
    "\n",
    "# Can't use pandas to read the table because it is a multi-level header\n",
    "# need to use beautiful soup to extract the table\n",
    "\n",
    "# Create a function to extract the tables from the url\n",
    "def extract_table(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    tables = soup.find_all('table')\n",
    "    return tables\n",
    "\n",
    "# Extract the tables from the url\n",
    "tables = extract_table(PAC12)\n",
    "\n",
    "# Read them into pandas\n",
    "current = pd.read_html(str(tables[1]))[0]\n",
    "\n",
    "# Remove citations from Enrollment\n",
    "current['Enrollment'] = current['Enrollment'].str.replace(r\"\\[.*\\]\", \"\")\n",
    "\n",
    "# Change any Joined date that are before 1959 to 1959\n",
    "current.loc[current['Joined'] < 1959, 'Joined'] = 1959\n",
    "\n",
    "# Add Left 2023 to all current members\n",
    "current['Left'] = 2023\n",
    "\n",
    "# Create the Standard Dataframe\n",
    "PAC12 = pd.DataFrame(columns=['Institution', 'Nickname', 'Location', 'Founded', 'Joined', 'Left', 'Enrollment', 'Conference'])\n",
    "\n",
    "# Add the data to the standard dataframe\n",
    "PAC12 = PAC12.append(current)\n",
    "\n",
    "# keep only the columns in the keep_cols list\n",
    "keep_cols = ['Institution', 'Nickname', 'Location', 'Founded', 'Joined', 'Left', 'Enrollment', 'Conference']\n",
    "\n",
    "PAC12 = PAC12[keep_cols]\n",
    "\n",
    "# Add conference name to Conference column\n",
    "PAC12['Conference'] = 'Pac-12 Conference'\n",
    "\n",
    "# Clean enrollment column of citations and commas - store as int\n",
    "PAC12['Enrollment'] = PAC12['Enrollment'].str.replace(r\"\\[.*\\]\", \"\")\n",
    "PAC12['Enrollment'] = PAC12['Enrollment'].str.replace(',', '')\n",
    "## Fill and nan values with 0\n",
    "PAC12['Enrollment'] = PAC12['Enrollment'].fillna(0)\n",
    "# store as int\n",
    "PAC12['Enrollment'] = PAC12['Enrollment'].astype(int)\n",
    "\n",
    "# Save to csv\n",
    "PAC12.to_csv('..\\TEMP\\conference_data\\PAC12.csv', index=False)\n",
    "\n",
    "PAC12\n",
    "\n",
    "# current\n",
    "former"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## American Athletic Conference\n",
    "\n",
    "# Use beautiful soup to extract the table\n",
    "\n",
    "# Create a function to extract the tables from the url\n",
    "def extract_table(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    tables = soup.find_all('table')\n",
    "    return tables\n",
    "\n",
    "# Extract the tables from the url\n",
    "tables = extract_table(AAC)\n",
    "\n",
    "# read them into pandas\n",
    "current = pd.read_html(str(tables[2]))[0]\n",
    "former = pd.read_html(str(tables[4]))[0]\n",
    "\n",
    "# Remove citation numbers from Founded in current\n",
    "current['Founded'] = current['Founded'].str.replace(r\"\\[.*\\]\", \"\")\n",
    "\n",
    "# Create the Standard Dataframe\n",
    "AAC = pd.DataFrame(columns=['Institution', 'Nickname', 'Location', 'Founded', 'Joined', 'Left', 'Enrollment', 'Conference'])\n",
    "\n",
    "# Combine The two dataframes into the standard dataframe\n",
    "AAC = AAC.append(current)\n",
    "AAC = AAC.append(former)\n",
    "\n",
    "AAC['Conference'] = 'American Athletic Conference'\n",
    "\n",
    "# Keep only the columns in the keep_cols list\n",
    "keep_cols = ['Institution', 'Nickname', 'Location', 'Founded', 'Joined', 'Left', 'Enrollment', 'Conference']\n",
    "\n",
    "AAC = AAC[keep_cols]\n",
    "\n",
    "# Remover citation numbers from Enrollment\n",
    "AAC['Enrollment'] = AAC['Enrollment'].str.replace(r\"\\[.*\\]\", \"\")\n",
    "# Remove commas\n",
    "AAC['Enrollment'] = AAC['Enrollment'].str.replace(',', '')\n",
    "# Fill in nan values with 0\n",
    "AAC['Enrollment'] = AAC['Enrollment'].fillna(0)\n",
    "# Convert to int\n",
    "AAC['Enrollment'] = AAC['Enrollment'].astype(int)\n",
    "\n",
    "# Clean UAB name\n",
    "AAC.loc[AAC['Institution'] == 'University of Alabama at Birmingham', 'Institution'] = 'UAB'\n",
    "\n",
    "# Save to csv\n",
    "AAC.to_csv('..\\TEMP\\conference_data\\AAC.csv', index=False)\n",
    "\n",
    "\n",
    "AAC\n",
    "\n",
    "\n",
    "# current\n",
    "# former\n",
    "\n",
    "# AAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Big East Conference\n",
    "\n",
    "# Use beautiful soup to extract the table\n",
    "\n",
    "# Create a function to extract the tables from the url\n",
    "def extract_table(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    tables = soup.find_all('table')\n",
    "    return tables\n",
    "\n",
    "# Extract the tables from the url\n",
    "tables = extract_table(BIGEAST)\n",
    "\n",
    "# Read the tables into pandas\n",
    "current = pd.read_html(str(tables[3]))[0]\n",
    "\n",
    "former = pd.read_html(str(tables[6]))[0]\n",
    "# Rename Location(Population) to Location and remover the numbers in parenthesis\n",
    "former = former.rename(columns={'Location(Population)': 'Location'})\n",
    "former['Location'] = former['Location'].str.replace(r\"\\(.*\\)\", \"\")\n",
    "current = current.rename(columns={'Location(Population)': 'Location'})\n",
    "current['Location'] = current['Location'].str.replace(r\"\\(.*\\)\", \"\")\n",
    "\n",
    "# Rename Beggining Year to Joined and Ending Year to Left\n",
    "former = former.rename(columns={'Beginning Year': 'Joined', 'Ending Year': 'Left'})\n",
    "\n",
    "# Rename YearJoined to Joined\n",
    "current = current.rename(columns={'YearJoined': 'Joined'})\n",
    "\n",
    "# Create the Standard Dataframe\n",
    "BIGEAST = pd.DataFrame(columns=['Institution', 'Nickname', 'Location', 'Founded', 'Joined', 'Left', 'Enrollment', 'Conference'])\n",
    "\n",
    "# Combine The two dataframes into the standard dataframe\n",
    "BIGEAST = BIGEAST.append(current)\n",
    "BIGEAST = BIGEAST.append(former)\n",
    "\n",
    "# Rename Miami to Miami (FL)\n",
    "BIGEAST.loc[BIGEAST['Institution'] == 'University of Miami', 'Institution'] = 'Miami (FL)'\n",
    "\n",
    "# Add Conference Name to Conference Column\n",
    "BIGEAST['Conference'] = 'Big East Conference'\n",
    "\n",
    "# Keep only the columns in the keep_cols list\n",
    "keep_cols = ['Institution', 'Nickname', 'Location', 'Founded', 'Joined', 'Left', 'Enrollment', 'Conference']\n",
    "\n",
    "BIGEAST = BIGEAST[keep_cols]\n",
    "\n",
    "# Remover citation numbers from Institution\n",
    "BIGEAST['Institution'] = BIGEAST['Institution'].str.replace(r\"\\[.*\\]\", \"\")\n",
    "\n",
    "# Save to csv\n",
    "BIGEAST.to_csv('..\\TEMP\\conference_data\\BIGEAST.csv', index=False)\n",
    "\n",
    "BIGEAST\n",
    "\n",
    "# current\n",
    "# former\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a master file from all of the individual conference files\n",
    "\n",
    "# Create a list of all the conference files\n",
    "import os\n",
    "\n",
    "# Create a list of all the conference files\n",
    "conference_files = os.listdir('..\\TEMP\\conference_data')\n",
    "# conference_files\n",
    "\n",
    "# Create a dataframe to hold all of the conference data\n",
    "master_df = pd.DataFrame(columns=['Institution', 'Nickname', 'Location', 'Founded', 'Joined', 'Left', 'Enrollment', 'Conference'])\n",
    "\n",
    "# Loop through the conference files and append them to the master dataframe\n",
    "for file in conference_files:\n",
    "    temp_df = pd.read_csv('..\\TEMP\\conference_data\\\\' + file)\n",
    "    master_df = master_df.append(temp_df)\n",
    "\n",
    "# Keep only the columns in the keep_cols list\n",
    "keep_cols = ['Institution', 'Nickname', 'Location', 'Founded', 'Joined', 'Left', 'Enrollment', 'Conference']\n",
    "master_df = master_df[keep_cols]\n",
    "\n",
    "# Clean up the Institution column\n",
    "master_df['Institution'] = master_df['Institution'].str.replace('University of ', '') # remove University of\n",
    "master_df['Institution'] = master_df['Institution'].str.replace('University', '') # remove University\n",
    "master_df['Institution'] = master_df['Institution'].str.replace('College of', '') # remove College of\n",
    "master_df['Institution'] = master_df['Institution'].str.replace('College', '') # remove College\n",
    "# remove citation numbers\n",
    "master_df['Institution'] = master_df['Institution'].str.replace(r\"\\[.*\\]\", \"\")\n",
    "# Strip whitespace\n",
    "master_df['Institution'] = master_df['Institution'].str.strip()\n",
    "\n",
    "##############################\n",
    "# Adjustments to Institution column\n",
    "###################################\n",
    "# Boston to Boston College to match the other files\n",
    "master_df.loc[master_df['Institution'] == 'Boston', 'Institution'] = 'Boston College'\n",
    "# Bowling Green State to Bowling Green\n",
    "master_df.loc[master_df['Institution'] == 'Bowling Green State', 'Institution'] = 'Bowling Green'\n",
    "# Middle Tennessee State to Middle Tennessee\n",
    "master_df.loc[master_df['Institution'] == 'Middle Tennessee State', 'Institution'] = 'Middle Tennessee'\n",
    "# Lousiana at Monroe to Louisiana-Monroe\n",
    "master_df.loc[master_df['Institution'] == 'Louisiana at Monroe', 'Institution'] = 'Louisiana-Monroe'\n",
    "# California, Berkley to California\n",
    "master_df.loc[master_df['Institution'] == 'California, Berkeley', 'Institution'] = 'California'\n",
    "# Southern Mississippi to Southern Miss\n",
    "master_df.loc[master_df['Institution'] == 'Southern Mississippi', 'Institution'] = 'Southern Miss'\n",
    "# Central Forida (UCF) to UCF\n",
    "master_df.loc[master_df['Institution'] == 'Central Florida (UCF)', 'Institution'] = 'UCF'\n",
    "# North Carolina at Charlotte to Charlotte\n",
    "master_df.loc[master_df['Institution'] == 'North Carolina at Charlotte', 'Institution'] = 'Charlotte'\n",
    "# Louisiana State to LSU\n",
    "master_df.loc[master_df['Institution'] == 'Louisiana State', 'Institution'] = 'LSU'\n",
    "# Texas at San Antonio\t to UTSA\n",
    "master_df.loc[master_df['Institution'] == 'Texas at San Antonio', 'Institution'] = 'UTSA'\n",
    "# Nevada, Las Vegas\tto UNLV\n",
    "master_df.loc[master_df['Institution'] == 'Nevada, Las Vegas', 'Institution'] = 'UNLV'\n",
    "# Colorado, Boulder\n",
    "master_df.loc[master_df['Institution'] == 'Colorado, Boulder', 'Institution'] = 'Colorado'\n",
    "# California, Los Angeles\tto UCLA\n",
    "master_df.loc[master_df['Institution'] == 'California, Los Angeles', 'Institution'] = 'UCLA'\n",
    "# Mississippi to Ole Miss\n",
    "master_df.loc[master_df['Institution'] == 'Mississippi', 'Institution'] = 'Ole Miss'\n",
    "# North Carolina State\tto NC State\n",
    "master_df.loc[master_df['Institution'] == 'North Carolina State', 'Institution'] = 'NC State'\n",
    "# Jacksonville to Jacksonville State\n",
    "master_df.loc[master_df['Institution'] == 'Jacksonville', 'Institution'] = 'Jacksonville State'\n",
    "# Brigham Young\t to BYU\n",
    "master_df.loc[master_df['Institution'] == 'Brigham Young', 'Institution'] = 'BYU'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Drop rows with empty values in Institution\n",
    "master_df = master_df.dropna(subset=['Institution'])\n",
    "\n",
    "# Save the master dataframe to a csv\n",
    "master_df.to_csv('..\\data\\cfb_conference_members.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the data\n",
    "cfb_data = master_df\n",
    "\n",
    "# Convert 'Joined' and 'Left' columns to datetime format\n",
    "cfb_data['Joined'] = pd.to_datetime(cfb_data['Joined'], format='%Y', errors='coerce')\n",
    "cfb_data['Left'] = pd.to_datetime(cfb_data['Left'], format='%Y', errors='coerce')\n",
    "\n",
    "# Recreate the yearly membership dataframe\n",
    "start_year = cfb_data['Joined'].min().year\n",
    "end_year = cfb_data['Joined'].max().year\n",
    "data_dict = {}\n",
    "for year in range(start_year, end_year + 1):\n",
    "    yearly_data = {}\n",
    "    for conference in cfb_data['Conference'].unique():\n",
    "        members = cfb_data[(cfb_data['Conference'] == conference) & \n",
    "                           (cfb_data['Joined'].dt.year <= year) & \n",
    "                           ((cfb_data['Left'].isnull()) | (cfb_data['Left'].dt.year > year))]['Institution'].tolist()\n",
    "        yearly_data[conference] = members\n",
    "    data_dict[year] = yearly_data\n",
    "yearly_members_df_corrected = pd.DataFrame.from_dict(data_dict, orient='index')\n",
    "\n",
    "# Compute the number of members for each conference over the years\n",
    "membership_counts = yearly_members_df_corrected.applymap(len)\n",
    "\n",
    "# Plotting the membership counts over time\n",
    "plt.figure(figsize=(14, 8))\n",
    "for column in membership_counts.columns:\n",
    "    plt.plot(membership_counts.index, membership_counts[column], label=column, marker='', linewidth=1.5)\n",
    "\n",
    "# Adding legend, labels and title\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Members')\n",
    "plt.title('Number of Members of Each Conference Over Time')\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as csv\n",
    "yearly_members_df_corrected.to_csv('..\\data\\yearly_conference_members.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## extract tables with pandas\n",
    "# SEC_tables = pd.read_html(SEC)\n",
    "# ACC_tables = pd.read_html(ACC)\n",
    "# # B1G_tables = pd.read_html(B1G)\n",
    "# # PAC12_tables = pd.read_html(PAC12)\n",
    "# BIG12_tables = pd.read_html(BIG12)\n",
    "# # AAC_tables = pd.read_html(AAC)\n",
    "# MWC_tables = pd.read_html(MWC)\n",
    "# MAC_tables = pd.read_html(MAC)\n",
    "# CUSA_tables = pd.read_html(CUSA)\n",
    "# SBC_tables = pd.read_html(SBC)\n",
    "\n",
    "# SWC_tables = pd.read_html(SWC)\n",
    "# WAC_tables = pd.read_html(WAC)\n",
    "# BIG8_tables = pd.read_html(BIG8)\n",
    "# # BIGEAST_tables = pd.read_html(BIGEAST)\n",
    "# IVY_tables = pd.read_html(IVY)\n",
    "# PCC_tables = pd.read_html(PCC)\n",
    "# BORDER_tables = pd.read_html(BORDER)\n",
    "# MVC_tables = pd.read_html(MVC)\n",
    "# SKYLINE_tables = pd.read_html(SKYLINE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract all the tables that list \"Current Members\" and \"Former Members\" from each conference's Wikipedia page\n",
    "## Store the tables in a list\n",
    "\n",
    "# tables = []\n",
    "\n",
    "# for url in urls:\n",
    "#     response = requests.get(url)\n",
    "#     soup = BeautifulSoup(response.text, 'html.parser')\n",
    "#     tables.append(soup.find_all('table', class_='wikitable'))\n",
    "\n",
    "# ## Create a list of the current members of each conference\n",
    "## Create a list of the former members of each conference\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
